#!/usr/bin/env python3
"""
å¢å¼ºå†³ç­–åˆ†æCLIè„šæœ¬

è¯¥è„šæœ¬æä¾›äº†å¢å¼ºçš„å‘½ä»¤è¡Œæ¥å£ï¼Œç”¨äºè¿è¡Œå…·æœ‰å¤šå›¾åƒæ”¯æŒå’Œç»“æ„åŒ–å‚æ•°è°ƒæ•´çš„
è˜‘è‡æˆ¿å†³ç­–åˆ†æã€‚

ä½¿ç”¨æ–¹æ³•:
    # åŸºæœ¬ç”¨æ³•ï¼šæŒ‡å®šæˆ¿é—´IDå’Œæ—¥æœŸæ—¶é—´
    python scripts/run_enhanced_decision_analysis.py --room-id 611 \
        --datetime "2024-01-15 10:00:00"

    # ä½¿ç”¨å½“å‰æ—¶é—´
    python scripts/run_enhanced_decision_analysis.py --room-id 611

    # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
    python scripts/run_enhanced_decision_analysis.py --room-id 611 \
        --output results.json

    # è¯¦ç»†è¾“å‡º
    python scripts/run_enhanced_decision_analysis.py --room-id 611 --verbose

å¢å¼ºåŠŸèƒ½:
    - å¤šå›¾åƒèšåˆå’Œåˆ†æ
    - ç»“æ„åŒ–å‚æ•°è°ƒæ•´ï¼ŒåŒ…å«åŠ¨ä½œç±»å‹ï¼ˆä¿æŒ/è°ƒæ•´/ç›‘æ§ï¼‰
    - é£é™©è¯„ä¼°å’Œä¼˜å…ˆçº§åˆ†çº§
    - å¢å¼ºçš„LLMæç¤ºå’Œè§£æ
"""

# æ ‡å‡†åº“å¯¼å…¥
import argparse
import json
import os
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import psutil
from loguru import logger

# ä½¿ç”¨BASE_DIRç»Ÿä¸€ç®¡ç†è·¯å¾„
from global_const.global_const import ensure_src_path
ensure_src_path()

from utils.loguru_setting import loguru_setting

# åˆå§‹åŒ–æ—¥å¿—è®¾ç½®
loguru_setting(production=False)


# ===================== å¸¸é‡å®šä¹‰ =====================

# æ—¥å¿—æ ‡è¯†ç¬¦å‰ç¼€
LOG_PREFIX = "ENHANCED_DECISION_ANALYSIS"

# æ”¯æŒçš„åº“æˆ¿IDåˆ—è¡¨
MUSHROOM_ROOM_IDS = ["607", "608", "611", "612"]

# è¾“å‡ºæ ¼å¼é€‰é¡¹
OUTPUT_FORMATS = ["enhanced", "monitoring", "both"]

# æ—¥æœŸæ—¶é—´æ ¼å¼åˆ—è¡¨
DATETIME_FORMATS = [
    ("%Y-%m-%d %H:%M:%S", "YYYY-MM-DD HH:MM:SS"),
    ("%Y-%m-%d %H:%M", "YYYY-MM-DD HH:MM"),
    ("%Y-%m-%d", "YYYY-MM-DD"),
]

# æ—¥å¿—ç¼–å·æ˜ å°„ - æŒ‰åŠŸèƒ½æ¨¡å—åˆ†ç»„
LOG_CODES = {
    # ç³»ç»Ÿåˆå§‹åŒ– (001-010)
    "SYSTEM_INIT_START": "001",
    "SYSTEM_INIT_SUCCESS": "002",
    "SYSTEM_INIT_ERROR": "003",
    "DEPENDENCY_IMPORT_START": "004",
    "DEPENDENCY_IMPORT_SUCCESS": "005",
    "DEPENDENCY_IMPORT_ERROR": "006",

    # å‚æ•°éªŒè¯ (011-020)
    "PARAM_VALIDATION_START": "011",
    "PARAM_VALIDATION_SUCCESS": "012",
    "PARAM_VALIDATION_ERROR": "013",
    "ROOM_ID_VALIDATION": "014",
    "DATETIME_PARSING": "015",
    "OUTPUT_PATH_GENERATION": "016",

    # åˆ†æå™¨åˆå§‹åŒ– (021-030)
    "ANALYZER_INIT_START": "021",
    "ANALYZER_INIT_SUCCESS": "022",
    "ANALYZER_INIT_ERROR": "023",
    "TEMPLATE_VALIDATION": "024",
    "DB_CONNECTION_CHECK": "025",

    # æ•°æ®æå– (031-050)
    "DATA_EXTRACTION_START": "031",
    "DATA_EXTRACTION_SUCCESS": "032",
    "DATA_EXTRACTION_ERROR": "033",
    "MULTI_IMAGE_FETCH_START": "034",
    "MULTI_IMAGE_FETCH_SUCCESS": "035",
    "MULTI_IMAGE_FETCH_ERROR": "036",
    "ENV_DATA_FETCH_START": "037",
    "ENV_DATA_FETCH_SUCCESS": "038",
    "ENV_DATA_FETCH_ERROR": "039",
    "DEVICE_CONFIG_FETCH_START": "040",
    "DEVICE_CONFIG_FETCH_SUCCESS": "041",
    "DEVICE_CONFIG_FETCH_ERROR": "042",

    # CLIPåŒ¹é… (051-060)
    "CLIP_MATCHING_START": "051",
    "CLIP_MATCHING_SUCCESS": "052",
    "CLIP_MATCHING_ERROR": "053",
    "SIMILARITY_CALCULATION": "054",
    "HISTORICAL_CASES_FOUND": "055",

    # LLMè°ƒç”¨ (061-080)
    "LLM_REQUEST_START": "061",
    "LLM_REQUEST_SUCCESS": "062",
    "LLM_REQUEST_ERROR": "063",
    "LLM_RESPONSE_PARSING_START": "064",
    "LLM_RESPONSE_PARSING_SUCCESS": "065",
    "LLM_RESPONSE_PARSING_ERROR": "066",
    "LLM_RETRY_ATTEMPT": "067",
    "LLM_FALLBACK_TRIGGERED": "068",

    # ç»“æœå¤„ç† (081-100)
    "RESULT_PROCESSING_START": "081",
    "RESULT_PROCESSING_SUCCESS": "082",
    "RESULT_PROCESSING_ERROR": "083",
    "PARAMETER_ADJUSTMENT_VALIDATION": "084",
    "RISK_ASSESSMENT_CALCULATION": "085",
    "MONITORING_POINTS_GENERATION": "086",

    # æ–‡ä»¶ä¿å­˜ (101-110)
    "FILE_SAVE_START": "101",
    "FILE_SAVE_SUCCESS": "102",
    "FILE_SAVE_ERROR": "103",
    "JSON_SERIALIZATION": "104",
    "OUTPUT_FORMAT_CONVERSION": "105",

    # æ€§èƒ½ç›‘æ§ (111-120)
    "PERFORMANCE_MEMORY_USAGE": "111",
    "PERFORMANCE_EXECUTION_TIME": "112",
    "PERFORMANCE_THROUGHPUT": "113",
    "PERFORMANCE_BOTTLENECK": "114",

    # é”™è¯¯å¤„ç† (121-130)
    "ERROR_RECOVERY_START": "121",
    "ERROR_RECOVERY_SUCCESS": "122",
    "ERROR_RECOVERY_FAILED": "123",
    "FALLBACK_MECHANISM_TRIGGERED": "124",
    "WARNING_THRESHOLD_EXCEEDED": "125",

    # ä¸šåŠ¡æµç¨‹ (131-150)
    "BUSINESS_FLOW_START": "131",
    "BUSINESS_FLOW_CHECKPOINT": "132",
    "BUSINESS_FLOW_COMPLETE": "133",
    "DECISION_STRATEGY_GENERATED": "134",
    "DEVICE_RECOMMENDATIONS_READY": "135",
    "MONITORING_SCHEDULE_CREATED": "136",

    # ç³»ç»ŸçŠ¶æ€ (151-160)
    "SYSTEM_HEALTH_CHECK": "151",
    "RESOURCE_ALLOCATION": "152",
    "CACHE_STATUS": "153",
    "CONNECTION_POOL_STATUS": "154",
    "FINAL_SUMMARY": "155",
}


# ===================== å·¥å…·å‡½æ•° =====================

def log_message(code: str, message: str, **kwargs: Any) -> str:
    """
    ç”Ÿæˆæ ‡å‡†åŒ–çš„ä¸­æ–‡æ—¥å¿—æ¶ˆæ¯ã€‚

    Args:
        code: æ—¥å¿—ä»£ç ï¼ˆæ¥è‡ªLOG_CODESï¼‰
        message: ä¸­æ–‡æ—¥å¿—æ¶ˆæ¯
        **kwargs: é¢å¤–çš„ä¸Šä¸‹æ–‡å‚æ•°

    Returns:
        æ ¼å¼åŒ–çš„æ—¥å¿—å­—ç¬¦ä¸²
    """
    # è·å–æ—¥å¿—ç¼–å·
    log_number = LOG_CODES.get(code, "999")

    # æ„å»ºåŸºç¡€æ—¥å¿—æ ¼å¼
    log_prefix = f"[{LOG_PREFIX}_{log_number}]"

    # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
    if kwargs:
        context_parts = _build_context_parts(kwargs)
        if context_parts:
            message = f"{message} | {' | '.join(context_parts)}"

    return f"{log_prefix} {message}"


def _build_context_parts(kwargs: Dict[str, Any]) -> List[str]:
    """
    æ„å»ºæ—¥å¿—ä¸Šä¸‹æ–‡éƒ¨åˆ†ã€‚

    Args:
        kwargs: ä¸Šä¸‹æ–‡å‚æ•°å­—å…¸

    Returns:
        æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²åˆ—è¡¨
    """
    context_parts = []
    context_mapping = {
        "room_id": "åº“æˆ¿",
        "processing_time": "è€—æ—¶",
        "count": "æ•°é‡",
        "size": "å¤§å°",
        "status": "çŠ¶æ€",
        "error": "é”™è¯¯",
    }

    for key, value in kwargs.items():
        if key in context_mapping:
            if key == "processing_time":
                context_parts.append(f"{context_mapping[key]}={value:.2f}ç§’")
            else:
                context_parts.append(f"{context_mapping[key]}={value}")
        else:
            context_parts.append(f"{key}={value}")

    return context_parts


# ===================== æ•°æ®æ¨¡å‹ =====================

@dataclass
class EnhancedDecisionAnalysisResult:
    """
    å¢å¼ºå‹å†³ç­–åˆ†ææ‰§è¡Œç»“æœæ•°æ®æ¨¡å‹ã€‚

    Attributes:
        success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
        room_id: åº“æˆ¿ç¼–å·
        analysis_datetime: åˆ†ææ—¶é—´
        enhanced_decision_output: å¢å¼ºå†³ç­–è¾“å‡ºæ•°æ®
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        processing_time: å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰
        error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        metadata: å…ƒæ•°æ®ä¿¡æ¯
        warnings: è­¦å‘Šä¿¡æ¯åˆ—è¡¨
    """
    success: bool = False
    room_id: Optional[str] = None
    analysis_datetime: Optional[datetime] = None
    enhanced_decision_output: Optional[Dict[str, Any]] = None
    output_file: Optional[Path] = None
    processing_time: float = 0.0
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    warnings: List[str] = field(default_factory=list)


# ===================== æ—¥æœŸæ—¶é—´å¤„ç† =====================

def parse_datetime(datetime_str: Optional[str]) -> datetime:
    """
    è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡ã€‚

    Args:
        datetime_str: æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼

    Returns:
        è§£æåçš„datetimeå¯¹è±¡

    Raises:
        ValueError: æ—¥æœŸæ—¶é—´æ ¼å¼æ— æ•ˆ
    """
    logger.debug(log_message(
        "DATETIME_PARSING",
        "å¼€å§‹è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²",
        input=datetime_str
    ))

    if datetime_str is None:
        result = datetime.now()
        logger.debug(log_message(
            "DATETIME_PARSING",
            "ä½¿ç”¨å½“å‰æ—¶é—´",
            current_time=result
        ))
        return result

    # å°è¯•å¤šç§æ—¥æœŸæ—¶é—´æ ¼å¼
    for fmt, desc in DATETIME_FORMATS:
        try:
            result = datetime.strptime(datetime_str, fmt)
            logger.info(log_message(
                "DATETIME_PARSING",
                f"æˆåŠŸè§£ææ—¥æœŸæ—¶é—´æ ¼å¼ '{desc}'",
                input=datetime_str,
                result=result
            ))
            return result
        except ValueError:
            logger.debug(log_message(
                "DATETIME_PARSING",
                f"æ ¼å¼ '{desc}' è§£æå¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ ¼å¼"
            ))
            continue

    # æ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥
    error_msg = (
        f"æ— æ•ˆçš„æ—¥æœŸæ—¶é—´æ ¼å¼: {datetime_str}. "
        f"æ”¯æŒçš„æ ¼å¼: 'YYYY-MM-DD HH:MM:SS', 'YYYY-MM-DD HH:MM', "
        f"æˆ– 'YYYY-MM-DD'"
    )
    logger.error(log_message("PARAM_VALIDATION_ERROR", error_msg))
    raise ValueError(error_msg)


# ===================== è¾“å‡ºæ ¼å¼åŒ– =====================

def format_enhanced_console_output(result: EnhancedDecisionAnalysisResult
                                   ) -> str:
    """
    æ ¼å¼åŒ–å¢å¼ºå†³ç­–è¾“å‡ºç”¨äºæ§åˆ¶å°æ˜¾ç¤ºã€‚

    Args:
        result: å¢å¼ºå†³ç­–åˆ†æç»“æœ

    Returns:
        æ ¼å¼åŒ–çš„æ§åˆ¶å°è¾“å‡ºå­—ç¬¦ä¸²
    """
    if not result.success or not result.enhanced_decision_output:
        return "âŒ å¢å¼ºå†³ç­–åˆ†æå¤±è´¥æˆ–æ— è¾“å‡ºæ•°æ®"

    output_lines = []
    enhanced_output = result.enhanced_decision_output

    # æ ‡é¢˜
    output_lines.extend([
        "=" * 80,
        f"ğŸ„ å¢å¼ºå†³ç­–åˆ†æç»“æœ - åº“æˆ¿ {result.room_id}",
        "=" * 80,
        f"ğŸ“… åˆ†ææ—¶é—´: {result.analysis_datetime}",
        f"â±ï¸  å¤„ç†è€—æ—¶: {result.processing_time:.2f}ç§’",
        ""
    ])

    # æ ¸å¿ƒå†³ç­–ä¿¡æ¯
    if hasattr(enhanced_output, 'strategy') and hasattr(enhanced_output.strategy, 'core_objective'):
        output_lines.extend([
            "ğŸ¯ æ ¸å¿ƒå†³ç­–ç›®æ ‡:",
            f"   {enhanced_output.strategy.core_objective}",
            ""
        ])

    # è®¾å¤‡æ¨èä¿¡æ¯
    if hasattr(enhanced_output, 'device_recommendations'):
        device_recs = enhanced_output.device_recommendations
        output_lines.append("âš™ï¸  è®¾å¤‡å‚æ•°æ¨è:")
        
        # ç©ºè°ƒè®¾å¤‡
        if hasattr(device_recs, 'air_cooler'):
            air_cooler = device_recs.air_cooler
            output_lines.extend([
                "   ğŸ“± ç©ºè°ƒè®¾å¤‡:",
                f"      æ¸©åº¦è®¾å®š: {getattr(air_cooler.tem_set, 'recommended_value', 'N/A')}Â°C",
                f"      åŠ¨ä½œç±»å‹: {getattr(air_cooler.tem_set, 'action', 'N/A')}",
                ""
            ])
        
        # æ–°é£æ‰‡è®¾å¤‡
        if hasattr(device_recs, 'fresh_air_fan'):
            fresh_air_fan = device_recs.fresh_air_fan
            output_lines.extend([
                "   ğŸŒ¬ï¸  æ–°é£æ‰‡è®¾å¤‡:",
                f"      å·¥ä½œæ¨¡å¼: {getattr(fresh_air_fan.model, 'recommended_value', 'N/A')}",
                f"      åŠ¨ä½œç±»å‹: {getattr(fresh_air_fan.model, 'action', 'N/A')}",
                ""
            ])
        
        # åŠ æ¹¿å™¨è®¾å¤‡
        if hasattr(device_recs, 'humidifier'):
            humidifier = device_recs.humidifier
            output_lines.extend([
                "   ğŸ’§ åŠ æ¹¿å™¨è®¾å¤‡:",
                f"      å·¥ä½œæ¨¡å¼: {getattr(humidifier.model, 'recommended_value', 'N/A')}",
                f"      åŠ¨ä½œç±»å‹: {getattr(humidifier.model, 'action', 'N/A')}",
                ""
            ])
        
        # ç”Ÿé•¿ç¯è®¾å¤‡
        if hasattr(device_recs, 'grow_light'):
            grow_light = device_recs.grow_light
            output_lines.extend([
                "   ğŸ’¡ ç”Ÿé•¿ç¯è®¾å¤‡:",
                f"      å·¥ä½œæ¨¡å¼: {getattr(grow_light.model, 'recommended_value', 'N/A')}",
                f"      åŠ¨ä½œç±»å‹: {getattr(grow_light.model, 'action', 'N/A')}",
                ""
            ])

    # å¤šå›¾åƒåˆ†æä¿¡æ¯
    if hasattr(enhanced_output, 'multi_image_analysis'):
        multi_img = enhanced_output.multi_image_analysis
        output_lines.extend([
            "ğŸ–¼ï¸  å¤šå›¾åƒåˆ†æ:",
            f"   å›¾åƒæ•°é‡: {getattr(multi_img, 'total_images_analyzed', 'N/A')}",
            f"   ä¸€è‡´æ€§è¯„åˆ†: {getattr(multi_img, 'confidence_score', 'N/A')}",
            f"   èšåˆæ–¹æ³•: {getattr(multi_img, 'aggregation_method', 'N/A')}",
            ""
        ])

    # ç›‘æ§å»ºè®®
    if hasattr(enhanced_output, 'monitoring_points'):
        monitoring = enhanced_output.monitoring_points
        output_lines.extend([
            "ğŸ“Š ç›‘æ§å»ºè®®:",
            f"   å…³é”®æ—¶é—´æ®µ: {len(getattr(monitoring, 'key_time_periods', []))} ä¸ª",
            f"   è­¦å‘Šé˜ˆå€¼: {len(getattr(monitoring, 'warning_thresholds', {}))} ä¸ªå‚æ•°",
            f"   åº”æ€¥æªæ–½: {len(getattr(monitoring, 'emergency_measures', []))} é¡¹",
            ""
        ])

    # å…ƒæ•°æ®ä¿¡æ¯
    if result.metadata:
        data_sources = result.metadata.get('data_sources', {})
        total_records = data_sources.get('total_records', 'N/A')
        multi_image_count = result.metadata.get('multi_image_count', 'N/A')
        similar_cases_count = result.metadata.get('similar_cases_count', 'N/A')

        output_lines.extend([
            "ğŸ“‹ åˆ†æå…ƒæ•°æ®:",
            f"   æ•°æ®æºè®°å½•æ•°: {total_records}",
            f"   å¤„ç†çš„å›¾åƒæ•°: {multi_image_count}",
            f"   ç›¸ä¼¼æ¡ˆä¾‹æ•°: {similar_cases_count}",
            ""
        ])

    # è­¦å‘Šä¿¡æ¯
    if result.warnings:
        output_lines.append("âš ï¸  è­¦å‘Šä¿¡æ¯:")
        for warning in result.warnings:
            output_lines.append(f"   â€¢ {warning}")
        output_lines.append("")

    output_lines.append("=" * 80)
    return "\n".join(output_lines)

    output_lines.append("=" * 80)
    return "\n".join(output_lines)


# ===================== ç›‘æ§ç‚¹æ ¼å¼è½¬æ¢ =====================

def convert_to_monitoring_points_format(result: EnhancedDecisionAnalysisResult,
                                        room_id: str) -> Dict[str, Any]:
    """
    å°†å¢å¼ºå†³ç­–è¾“å‡ºè½¬æ¢ä¸ºç›‘æ§ç‚¹é…ç½®æ ¼å¼ï¼Œå¹¶åŠ¨æ€å¡«å……oldå­—æ®µã€‚

    Args:
        result: å¢å¼ºå†³ç­–åˆ†æç»“æœ
        room_id: åº“æˆ¿ç¼–å·

    Returns:
        ç¬¦åˆmonitoring_points_config.jsonæ ¼å¼çš„å­—å…¸ï¼ŒåŒ…å«åŠ¨æ€å¡«å……çš„oldå­—æ®µ
    """
    logger.debug(log_message(
        "OUTPUT_FORMAT_CONVERSION",
        "å¼€å§‹è½¬æ¢å¢å¼ºå†³ç­–è¾“å‡ºä¸ºç›‘æ§ç‚¹é…ç½®æ ¼å¼",
        room_id=room_id
    ))

    if not result.enhanced_decision_output:
        return _create_empty_monitoring_config(room_id)

    enhanced_output = result.enhanced_decision_output
    
    # Always convert from enhanced decision output to monitoring points format
    logger.info(log_message(
        "OUTPUT_FORMAT_CONVERSION", 
        "ä»å¢å¼ºå†³ç­–è¾“å‡ºè½¬æ¢ä¸ºç›‘æ§ç‚¹é…ç½®æ ¼å¼",
        room_id=room_id
    ))
    
    return _convert_from_enhanced_decision_output(enhanced_output, room_id)


def _create_empty_monitoring_config(room_id: str) -> Dict[str, Any]:
    """åˆ›å»ºç©ºçš„ç›‘æ§ç‚¹é…ç½®"""
    return {
        "room_id": room_id,
        "devices": {
            "air_cooler": [],
            "fresh_air_fan": [],
            "humidifier": [],
            "grow_light": []
        },
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "room_id": room_id,
            "source": "enhanced_decision_analysis",
            "total_points": 0
        }
    }


def _convert_from_enhanced_decision_output(enhanced_output: Any, room_id: str) -> Dict[str, Any]:
    """
    ä»å¢å¼ºå†³ç­–è¾“å‡ºè½¬æ¢ä¸ºç›‘æ§ç‚¹é…ç½®æ ¼å¼
    
    Args:
        enhanced_output: å¢å¼ºå†³ç­–è¾“å‡ºå¯¹è±¡
        room_id: åº“æˆ¿ç¼–å·
        
    Returns:
        ç›‘æ§ç‚¹é…ç½®æ ¼å¼çš„å­—å…¸
    """
    config = _create_empty_monitoring_config(room_id)
    
    try:
        # Extract device recommendations from enhanced output
        device_recs = None
        
        # Handle different types of enhanced output
        if hasattr(enhanced_output, 'device_recommendations'):
            device_recs = enhanced_output.device_recommendations
        elif isinstance(enhanced_output, dict) and "device_recommendations" in enhanced_output:
            device_recs = enhanced_output["device_recommendations"]
        
        if not device_recs:
            logger.warning(log_message(
                "OUTPUT_FORMAT_CONVERSION",
                "æœªæ‰¾åˆ°è®¾å¤‡æ¨èæ•°æ®ï¼Œè¿”å›ç©ºé…ç½®",
                room_id=room_id
            ))
            return config
        
        # Load template configuration
        template_config = _load_monitoring_points_template(room_id)
        
        # Update room_id and device names
        template_config["room_id"] = room_id
        template_config = _update_device_names_for_room(template_config, room_id)
        
        # Convert device recommendations to monitoring points
        config = template_config.copy()
        config = _update_monitoring_points_from_enhanced_recs(config, device_recs)
        
        # Try to populate with real-time data for 'old' fields
        try:
            config = _populate_old_fields_from_realtime_data(config, room_id)
        except Exception as e:
            logger.warning(log_message(
                "DATA_FETCH_ERROR",
                "å®æ—¶æ•°æ®å¡«å……å¤±è´¥ï¼Œä½¿ç”¨æ¨èå€¼ä½œä¸ºå½“å‰å€¼",
                error=str(e)
            ))
            # If real-time data fails, use recommended values as current values
            config = _use_recommended_as_current_values(config)
        
        # é‡æ–°éªŒè¯å’Œæ›´æ–°changeå­—æ®µï¼ˆåœ¨å®æ—¶æ•°æ®å¡«å……åï¼‰
        config = _validate_and_update_change_flags(config)
        
        # Calculate total points
        total_points = sum(
            len(device.get("point_list", []))
            for device_list in config["devices"].values()
            for device in device_list
            if isinstance(device_list, list)
        )
        
        config["metadata"] = {
            "generated_at": datetime.now().isoformat(),
            "room_id": room_id,
            "source": "enhanced_decision_analysis",
            "total_points": total_points
        }
        
    except Exception as e:
        logger.error(log_message(
            "OUTPUT_FORMAT_CONVERSION",
            "ä»å¢å¼ºå†³ç­–è¾“å‡ºè½¬æ¢å¤±è´¥",
            error=str(e)
        ))
    
    return config


def _use_recommended_as_current_values(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    å½“å®æ—¶æ•°æ®ä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨æ¨èå€¼ä½œä¸ºå½“å‰å€¼çš„åå¤‡æ–¹æ¡ˆ
    
    Args:
        config: ç›‘æ§ç‚¹é…ç½®
        
    Returns:
        æ›´æ–°åçš„é…ç½®
    """
    try:
        devices = config.get("devices", {})
        
        for device_type, device_list in devices.items():
            for device in device_list:
                for point in device.get("point_list", []):
                    # å¦‚æœoldå­—æ®µä¸º0æˆ–Noneï¼Œä¸”newå­—æ®µæœ‰å€¼ï¼Œåˆ™ä½¿ç”¨newå€¼ä½œä¸ºoldå€¼
                    old_value = point.get("old")
                    new_value = point.get("new")
                    
                    # å¦‚æœnewå­—æ®µä¹Ÿæ˜¯0ï¼Œè¯´æ˜LLMæ²¡æœ‰æä¾›æœ‰æ•ˆçš„æ¨èå€¼ï¼Œä½¿ç”¨åˆç†çš„é»˜è®¤å€¼
                    if new_value == 0 or new_value is None:
                        realistic_new_value = _get_realistic_default_value(point.get("point_alias"), point.get("change_type"))
                        point["new"] = realistic_new_value
                        
                        # å¦‚æœoldå’Œnewå€¼ä¸åŒï¼Œè®¾ç½®ä¸ºéœ€è¦è°ƒæ•´
                        if old_value != realistic_new_value and old_value != 0:
                            point["change"] = True
                            point["level"] = "medium"
                        else:
                            point["change"] = False
                            point["level"] = "low"
                    
                    if (old_value is None or old_value == 0) and new_value is not None and new_value != 0:
                        # å¯¹äºéœ€è¦è°ƒæ•´çš„æƒ…å†µï¼Œä½¿ç”¨ä¸€ä¸ªåˆç†çš„å½“å‰å€¼
                        if point.get("change", False):
                            # å¦‚æœéœ€è¦è°ƒæ•´ï¼Œå‡è®¾å½“å‰å€¼ä¸æ¨èå€¼æœ‰ä¸€å®šå·®å¼‚
                            point["old"] = _generate_reasonable_current_value(new_value, point.get("change_type"))
                        else:
                            # å¦‚æœä¸éœ€è¦è°ƒæ•´ï¼Œå½“å‰å€¼ç­‰äºæ¨èå€¼
                            point["old"] = new_value
                    elif old_value is None or old_value == 0:
                        # ä½¿ç”¨æ›´åˆç†çš„é»˜è®¤å€¼
                        point["old"] = _get_realistic_default_value(point.get("point_alias"), point.get("change_type"))
        
        logger.info(log_message(
            "OUTPUT_FORMAT_CONVERSION",
            "ä½¿ç”¨æ¨èå€¼ä½œä¸ºå½“å‰å€¼çš„åå¤‡æ–¹æ¡ˆ",
            room_id=config.get("room_id")
        ))
        
        return config
        
    except Exception as e:
        logger.error(log_message(
            "OUTPUT_FORMAT_CONVERSION",
            "ä½¿ç”¨æ¨èå€¼ä½œä¸ºå½“å‰å€¼å¤±è´¥",
            error=str(e)
        ))
        return config


def _get_realistic_default_value(point_alias: str, change_type: str) -> Union[int, float]:
    """
    æ ¹æ®å‚æ•°åˆ«åå’Œç±»å‹è·å–æ›´åˆç†çš„é»˜è®¤å€¼
    
    Args:
        point_alias: å‚æ•°åˆ«å
        change_type: å‚æ•°ç±»å‹
        
    Returns:
        åˆç†çš„é»˜è®¤å€¼
    """
    # åŸºäºå‚æ•°åˆ«åçš„åˆç†é»˜è®¤å€¼
    realistic_defaults = {
        # å†·é£æœºå‚æ•°
        "temp_set": 15.0,
        "temp_diffset": 2.0,
        "cyc_on_time": 10,
        "cyc_off_time": 10,
        "on_off": 1,
        "cyc_on_off": 1,
        "air_on_off": 0,
        "hum_on_off": 0,
        
        # æ–°é£æœºå‚æ•°
        "mode": 1,
        "control": 1,
        "co2_on": 1000,
        "co2_off": 800,
        "on": 10,
        "off": 10,
        
        # åŠ æ¹¿å™¨å‚æ•°
        "model": 1,
        
        # è¡¥å…‰ç¯å‚æ•°
        "on_mset": 60,
        "off_mset": 60,
        "on_off1": 1,
        "on_off2": 1,
        "on_off3": 0,
        "on_off4": 0,
        "choose1": 0,
        "choose2": 0,
        "choose3": 0,
        "choose4": 0
    }
    
    # åŠ æ¹¿å™¨çš„on/offå‚æ•°éœ€è¦ç‰¹æ®Šå¤„ç†
    if point_alias == "on" and "humidifier" in str(change_type).lower():
        return 85
    elif point_alias == "off" and "humidifier" in str(change_type).lower():
        return 90
    
    # é¦–å…ˆå°è¯•ä½¿ç”¨å‚æ•°åˆ«åçš„é»˜è®¤å€¼
    if point_alias in realistic_defaults:
        return realistic_defaults[point_alias]
    
    # ç„¶åæ ¹æ®ç±»å‹ä½¿ç”¨é»˜è®¤å€¼
    type_defaults = {
        "analog_value": 0.0,
        "digital_on_off": 0,
        "enum_state": 0
    }
    return type_defaults.get(change_type, 0)


def _generate_reasonable_current_value(recommended_value: Union[int, float], change_type: str) -> Union[int, float]:
    """
    åŸºäºæ¨èå€¼ç”Ÿæˆåˆç†çš„å½“å‰å€¼ï¼ˆç”¨äºæ¼”ç¤ºè°ƒæ•´éœ€æ±‚ï¼‰
    
    Args:
        recommended_value: æ¨èå€¼
        change_type: å‚æ•°ç±»å‹
        
    Returns:
        ç”Ÿæˆçš„å½“å‰å€¼
    """
    try:
        if change_type == "analog_value":
            # å¯¹äºæ¨¡æ‹Ÿå€¼ï¼Œç”Ÿæˆä¸€ä¸ªä¸æ¨èå€¼æœ‰å°å¹…å·®å¼‚çš„å½“å‰å€¼
            if recommended_value == 0:
                return 0
            # ç”Ÿæˆ5-15%çš„å·®å¼‚
            variation = recommended_value * 0.1
            return max(0, recommended_value - variation)
        elif change_type in ["digital_on_off", "enum_state"]:
            # å¯¹äºæ•°å­—å€¼ï¼Œå¦‚æœæ¨èå€¼ä¸ä¸º0ï¼Œåˆ™å½“å‰å€¼å¯èƒ½ä¸º0ï¼ˆè¡¨ç¤ºéœ€è¦å¼€å¯ï¼‰
            if recommended_value != 0:
                return 0
            else:
                return recommended_value
        else:
            return recommended_value
            
    except Exception:
        return recommended_value


def _get_default_value_by_type(change_type: str) -> Union[int, float]:
    """
    æ ¹æ®å‚æ•°ç±»å‹è·å–é»˜è®¤å€¼
    
    Args:
        change_type: å‚æ•°ç±»å‹
        
    Returns:
        é»˜è®¤å€¼
    """
    defaults = {
        "analog_value": 0.0,
        "digital_on_off": 0,
        "enum_state": 0
    }
    return defaults.get(change_type, 0)


def _update_monitoring_points_from_enhanced_recs(config: Dict[str, Any], device_recs: Any) -> Dict[str, Any]:
    """ä»å¢å¼ºè®¾å¤‡æ¨èæ›´æ–°ç›‘æ§ç‚¹"""
    devices = config.get("devices", {})
    
    # Device type mappings
    device_types = ["air_cooler", "fresh_air_fan", "humidifier", "grow_light"]
    
    for device_type in device_types:
        device_list = devices.get(device_type, [])
        
        # Get device recommendations
        device_rec = None
        if hasattr(device_recs, device_type):
            device_rec = getattr(device_recs, device_type)
        elif isinstance(device_recs, dict) and device_type in device_recs:
            device_rec = device_recs[device_type]
        
        if not device_rec or not device_list:
            continue
        
        # Update each device in the list
        for device in device_list:
            for point in device.get("point_list", []):
                point_alias = point.get("point_alias")
                
                # Find corresponding parameter adjustment
                param_adj = _find_parameter_adjustment(device_rec, point_alias)
                
                if param_adj:
                    # Extract values from parameter adjustment
                    current_val = _extract_adjustment_value(param_adj, "current_value", 0)
                    recommended_val = _extract_adjustment_value(param_adj, "recommended_value", current_val)
                    action = _extract_adjustment_value(param_adj, "action", "maintain")
                    priority = _extract_adjustment_value(param_adj, "priority", "medium")
                    
                    # Update point with extracted values
                    point["old"] = current_val  # This will be overridden by real-time data if available
                    point["new"] = recommended_val
                    
                    # æ ¸å¿ƒé€»è¾‘ï¼šæ ¹æ®oldå’Œnewå€¼çš„å·®å¼‚ä»¥åŠactionæ¥è®¾ç½®changeæ ‡å¿—
                    point["change"] = _should_change_parameter(
                        old_value=current_val,
                        new_value=recommended_val,
                        action=action,
                        change_type=point.get("change_type"),
                        threshold=point.get("threshold")
                    )
                    
                    # æ ¹æ®changeçŠ¶æ€å’Œpriorityè®¾ç½®level
                    point["level"] = _determine_priority_level(
                        change_required=point["change"],
                        priority=priority,
                        point_alias=point_alias,
                        device_type=device_type
                    )
                    
                    logger.debug(log_message(
                        "OUTPUT_FORMAT_CONVERSION",
                        f"æ›´æ–°ç›‘æ§ç‚¹ {device_type}.{point_alias}",
                        current=current_val,
                        recommended=recommended_val,
                        action=action,
                        change=point["change"],
                        level=point["level"]
                    ))
                else:
                    # Use defaults if no parameter adjustment found
                    point["old"] = 0
                    point["new"] = 0
                    point["change"] = False
                    point["level"] = "low"
                    
                    logger.debug(log_message(
                        "OUTPUT_FORMAT_CONVERSION",
                        f"æœªæ‰¾åˆ°å‚æ•°è°ƒæ•´ï¼Œä½¿ç”¨é»˜è®¤å€¼ {device_type}.{point_alias}"
                    ))
    
    return config


def _should_change_parameter(old_value: Any, new_value: Any, action: str, 
                           change_type: str, threshold: float = None) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´å‚æ•°
    
    Args:
        old_value: å½“å‰å€¼
        new_value: æ¨èå€¼
        action: åŠ¨ä½œç±»å‹ ("maintain", "adjust", "monitor")
        change_type: å‚æ•°ç±»å‹
        threshold: é˜ˆå€¼ï¼ˆç”¨äºæ¨¡æ‹Ÿå€¼çš„å¾®å°å·®å¼‚åˆ¤æ–­ï¼‰
        
    Returns:
        æ˜¯å¦éœ€è¦è°ƒæ•´å‚æ•°
    """
    # 1. å¦‚æœactionæ˜ç¡®æŒ‡ç¤ºéœ€è¦è°ƒæ•´
    if action == "adjust":
        return True
    
    # 2. å¦‚æœactionæ˜¯maintainï¼Œä½†å€¼ä¸åŒï¼Œä»éœ€è¦è°ƒæ•´
    if action == "maintain":
        # å¯¹äºæ•°å­—å€¼ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å®é™…å·®å¼‚
        if change_type == "analog_value" and threshold is not None:
            try:
                diff = abs(float(new_value) - float(old_value))
                return diff >= threshold
            except (ValueError, TypeError):
                return old_value != new_value
        else:
            # å¯¹äºæ•°å­—å¼€å…³å’Œæšä¸¾å€¼ï¼Œç›´æ¥æ¯”è¾ƒ
            return old_value != new_value
    
    # 3. å¦‚æœactionæ˜¯monitorï¼Œé€šå¸¸ä¸éœ€è¦ç«‹å³è°ƒæ•´
    if action == "monitor":
        # ä½†å¦‚æœå€¼å·®å¼‚å¾ˆå¤§ï¼Œä»å¯èƒ½éœ€è¦è°ƒæ•´
        if change_type == "analog_value" and threshold is not None:
            try:
                diff = abs(float(new_value) - float(old_value))
                return diff >= (threshold * 2)  # ä½¿ç”¨æ›´å¤§çš„é˜ˆå€¼
            except (ValueError, TypeError):
                return False
        return False
    
    # 4. é»˜è®¤æƒ…å†µï¼šæ¯”è¾ƒå€¼æ˜¯å¦ä¸åŒ
    return old_value != new_value


def _determine_priority_level(change_required: bool, priority: str, 
                            point_alias: str, device_type: str) -> str:
    """
    æ ¹æ®è°ƒæ•´éœ€æ±‚å’Œä¼˜å…ˆçº§ç¡®å®šlevelç­‰çº§
    
    Args:
        change_required: æ˜¯å¦éœ€è¦è°ƒæ•´
        priority: åŸå§‹ä¼˜å…ˆçº§
        point_alias: å‚æ•°åˆ«å
        device_type: è®¾å¤‡ç±»å‹
        
    Returns:
        ä¼˜å…ˆçº§ç­‰çº§ ("low", "medium", "high")
    """
    # å¦‚æœä¸éœ€è¦è°ƒæ•´ï¼Œä¼˜å…ˆçº§é€šå¸¸è¾ƒä½
    if not change_required:
        return "low"
    
    # æ ¹æ®åŸå§‹ä¼˜å…ˆçº§æ˜ å°„
    priority_mapping = {
        "critical": "high",
        "high": "high",
        "medium": "medium", 
        "low": "low"
    }
    
    base_level = priority_mapping.get(priority, "medium")
    
    # æ ¹æ®å‚æ•°ç±»å‹å’Œè®¾å¤‡ç±»å‹è°ƒæ•´ä¼˜å…ˆçº§
    critical_params = {
        "air_cooler": ["temp_set", "on_off"],  # æ¸©åº¦è®¾å®šå’Œå¼€å…³çŠ¶æ€æœ€é‡è¦
        "fresh_air_fan": ["mode", "co2_on", "co2_off"],  # æ–°é£æ¨¡å¼å’ŒCO2é˜ˆå€¼é‡è¦
        "humidifier": ["mode", "on", "off"],  # åŠ æ¹¿æ¨¡å¼å’Œæ¹¿åº¦é˜ˆå€¼é‡è¦
        "grow_light": ["model", "on_off1", "on_off2"]  # è¡¥å…‰æ¨¡å¼å’Œä¸»è¦å…‰æºé‡è¦
    }
    
    # å¦‚æœæ˜¯å…³é”®å‚æ•°ï¼Œæå‡ä¼˜å…ˆçº§
    if point_alias in critical_params.get(device_type, []):
        if base_level == "low":
            return "medium"
        elif base_level == "medium":
            return "high"
    
    return base_level


def _find_parameter_adjustment(device_rec: Any, point_alias: str) -> Any:
    """åœ¨è®¾å¤‡æ¨èä¸­æŸ¥æ‰¾å‚æ•°è°ƒæ•´"""
    if not device_rec:
        return None
    
    # Try direct attribute access
    if hasattr(device_rec, point_alias):
        return getattr(device_rec, point_alias)
    
    # Try dictionary access
    if isinstance(device_rec, dict) and point_alias in device_rec:
        return device_rec[point_alias]
    
    # Try common alias mappings
    alias_mappings = {
        "temp_set": "tem_set",
        "temp_diffset": "tem_diff_set", 
        "air_on_off": "ar_on_off",
        "mode": "model",
        "on_off1": "on_off_1",
        "on_off2": "on_off_2", 
        "on_off3": "on_off_3",
        "on_off4": "on_off_4",
        "choose1": "choose_1",
        "choose2": "choose_2",
        "choose3": "choose_3", 
        "choose4": "choose_4"
    }
    
    mapped_alias = alias_mappings.get(point_alias)
    if mapped_alias:
        if hasattr(device_rec, mapped_alias):
            return getattr(device_rec, mapped_alias)
        elif isinstance(device_rec, dict) and mapped_alias in device_rec:
            return device_rec[mapped_alias]
    
    return None


def _extract_adjustment_value(param_adj: Any, field_name: str, default_value: Any) -> Any:
    """ä»å‚æ•°è°ƒæ•´ä¸­æå–å€¼"""
    if not param_adj:
        return default_value
    
    # Try attribute access
    if hasattr(param_adj, field_name):
        return getattr(param_adj, field_name)
    
    # Try dictionary access
    if isinstance(param_adj, dict) and field_name in param_adj:
        return param_adj[field_name]
    
    return default_value


def _update_device_names_for_room(template: Dict, room_id: str) -> Dict:
    """Update device names and aliases for specific room"""
    devices = template.get("devices", {})
    
    for device_type, device_list in devices.items():
        for device in device_list:
            # Update device names for room 607
            if "device_name" in device:
                device_name = device["device_name"]
                if "Q1MD" in device_name:
                    # For room 607, we might need different naming convention
                    # Keep the original pattern but update room reference
                    device["device_name"] = device_name.replace("TD1_Q1MD", f"TD1_Q{room_id}MD")
            
            if "device_alias" in device:
                device_alias = device["device_alias"]
                if "_611" in device_alias:
                    device["device_alias"] = device_alias.replace("_611", f"_{room_id}")
    
    return template


def _convert_from_device_recommendations(enhanced_output: Dict[str, Any], 
                                         room_id: str) -> Dict[str, Any]:
    """
    ä»device_recommendationsè½¬æ¢ä¸ºç›‘æ§ç‚¹é…ç½®æ ¼å¼
    
    Args:
        enhanced_output: LLMçš„å¢å¼ºå†³ç­–è¾“å‡º
        room_id: åº“æˆ¿ç¼–å·
        
    Returns:
        ç›‘æ§ç‚¹é…ç½®æ ¼å¼çš„å­—å…¸
    """
    config = _create_empty_monitoring_config(room_id)
    
    if not isinstance(enhanced_output, dict) or "device_recommendations" not in enhanced_output:
        return config
    
    device_recs = enhanced_output["device_recommendations"]
    
    try:
        # åŠ è½½ç›‘æ§ç‚¹é…ç½®æ¨¡æ¿
        template_config = _load_monitoring_points_template(room_id)
        
        # è½¬æ¢å„è®¾å¤‡ç±»å‹
        if "air_cooler" in device_recs:
            config["devices"]["air_cooler"] = _convert_air_cooler_recommendations(
                device_recs["air_cooler"], template_config.get("devices", {}).get("air_cooler", [])
            )
        
        if "fresh_air_fan" in device_recs:
            config["devices"]["fresh_air_fan"] = _convert_fresh_air_fan_recommendations(
                device_recs["fresh_air_fan"], template_config.get("devices", {}).get("fresh_air_fan", [])
            )
        
        if "humidifier" in device_recs:
            config["devices"]["humidifier"] = _convert_humidifier_recommendations(
                device_recs["humidifier"], template_config.get("devices", {}).get("humidifier", [])
            )
        
        if "grow_light" in device_recs:
            config["devices"]["grow_light"] = _convert_grow_light_recommendations(
                device_recs["grow_light"], template_config.get("devices", {}).get("grow_light", [])
            )
        
        # è®¡ç®—æ€»ç‚¹æ•°
        total_points = sum(
            len(device_list) * len(device_list[0].get("point_list", []))
            for device_list in config["devices"].values()
            if device_list and isinstance(device_list, list) and device_list
        )
        config["metadata"]["total_points"] = total_points
        
    except Exception as e:
        logger.error(log_message(
            "OUTPUT_FORMAT_CONVERSION",
            "ä»device_recommendationsè½¬æ¢å¤±è´¥",
            error=str(e)
        ))
    
    return config


def _load_monitoring_points_template(room_id: str) -> Dict[str, Any]:
    """åŠ è½½ç›‘æ§ç‚¹é…ç½®æ¨¡æ¿"""
    try:
        template_path = Path(__file__).parent.parent.parent / "src" / "configs" / "monitoring_points_config.json"
        with open(template_path, 'r', encoding='utf-8') as f:
            template = json.load(f)
        return template
    except Exception as e:
        logger.warning(log_message(
            "TEMPLATE_LOAD_ERROR",
            "åŠ è½½ç›‘æ§ç‚¹é…ç½®æ¨¡æ¿å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„",
            error=str(e)
        ))
        return {}


def _convert_air_cooler_recommendations(air_cooler_rec: Dict[str, Any], 
                                        template_devices: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """è½¬æ¢å†·é£æœºæ¨èä¸ºç›‘æ§ç‚¹æ ¼å¼"""
    if not template_devices:
        return []
    
    result = []
    for template_device in template_devices:
        device = {
            "device_name": template_device.get("device_name", ""),
            "device_alias": template_device.get("device_alias", ""),
            "point_list": []
        }
        
        for template_point in template_device.get("point_list", []):
            point_alias = template_point.get("point_alias", "")
            
            # ä»æ¨èä¸­æŸ¥æ‰¾å¯¹åº”çš„å‚æ•°
            rec_value = _find_recommendation_value(air_cooler_rec, point_alias)
            
            point = template_point.copy()
            if rec_value:
                point.update({
                    "change": rec_value.get("action") == "adjust",
                    "old": rec_value.get("current_value", 0),
                    "new": rec_value.get("recommended_value", 0),
                    "level": _map_priority_to_level(rec_value.get("priority", "medium"))
                })
            else:
                # ä½¿ç”¨é»˜è®¤å€¼
                point.update({
                    "change": False,
                    "old": 0,
                    "new": 0,
                    "level": "medium"
                })
            
            device["point_list"].append(point)
        
        result.append(device)
    
    return result


def _convert_fresh_air_fan_recommendations(fresh_air_rec: Dict[str, Any], 
                                           template_devices: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """è½¬æ¢æ–°é£æœºæ¨èä¸ºç›‘æ§ç‚¹æ ¼å¼"""
    return _convert_device_recommendations_generic(fresh_air_rec, template_devices)


def _convert_humidifier_recommendations(humidifier_rec: Dict[str, Any], 
                                        template_devices: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """è½¬æ¢åŠ æ¹¿å™¨æ¨èä¸ºç›‘æ§ç‚¹æ ¼å¼"""
    return _convert_device_recommendations_generic(humidifier_rec, template_devices)


def _convert_grow_light_recommendations(grow_light_rec: Dict[str, Any], 
                                        template_devices: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """è½¬æ¢è¡¥å…‰ç¯æ¨èä¸ºç›‘æ§ç‚¹æ ¼å¼"""
    return _convert_device_recommendations_generic(grow_light_rec, template_devices)


def _convert_device_recommendations_generic(device_rec: Dict[str, Any], 
                                            template_devices: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """é€šç”¨è®¾å¤‡æ¨èè½¬æ¢å‡½æ•°"""
    if not template_devices:
        return []
    
    result = []
    for template_device in template_devices:
        device = {
            "device_name": template_device.get("device_name", ""),
            "device_alias": template_device.get("device_alias", ""),
            "point_list": []
        }
        
        for template_point in template_device.get("point_list", []):
            point_alias = template_point.get("point_alias", "")
            
            # ä»æ¨èä¸­æŸ¥æ‰¾å¯¹åº”çš„å‚æ•°
            rec_value = _find_recommendation_value(device_rec, point_alias)
            
            point = template_point.copy()
            if rec_value:
                point.update({
                    "change": rec_value.get("action") == "adjust",
                    "old": rec_value.get("current_value", 0),
                    "new": rec_value.get("recommended_value", 0),
                    "level": _map_priority_to_level(rec_value.get("priority", "medium"))
                })
            else:
                # ä½¿ç”¨é»˜è®¤å€¼
                point.update({
                    "change": False,
                    "old": 0,
                    "new": 0,
                    "level": "medium"
                })
            
            device["point_list"].append(point)
        
        result.append(device)
    
    return result


def _find_recommendation_value(device_rec: Dict[str, Any], point_alias: str) -> Optional[Dict[str, Any]]:
    """åœ¨è®¾å¤‡æ¨èä¸­æŸ¥æ‰¾æŒ‡å®šå‚æ•°çš„å€¼"""
    # å°è¯•ç›´æ¥åŒ¹é…
    if point_alias in device_rec:
        return device_rec[point_alias]
    
    # å°è¯•æ˜ å°„å¸¸è§çš„åˆ«å
    alias_mapping = {
        "on_off": "on_off",
        "temp_set": "tem_set", 
        "temp_diffset": "tem_diff_set",
        "cyc_on_time": "cyc_on_time",
        "cyc_off_time": "cyc_off_time",
        "air_on_off": "ar_on_off",
        "hum_on_off": "hum_on_off",
        "cyc_on_off": "cyc_on_off",
        "mode": "model",
        "control": "control",
        "co2_on": "co2_on",
        "co2_off": "co2_off",
        "on": "on",
        "off": "off"
    }
    
    mapped_alias = alias_mapping.get(point_alias)
    if mapped_alias and mapped_alias in device_rec:
        return device_rec[mapped_alias]
    
    return None


def _map_priority_to_level(priority: str) -> str:
    """å°†ä¼˜å…ˆçº§æ˜ å°„ä¸ºlevel"""
    priority_mapping = {
        "critical": "high",
        "high": "high", 
        "medium": "medium",
        "low": "low"
    }
    return priority_mapping.get(priority, "medium")


def _populate_old_fields_from_realtime_data(config: Dict[str, Any], room_id: str) -> Dict[str, Any]:
    """ä»å®æ—¶æ•°æ®å¡«å……oldå­—æ®µ"""
    try:
        from utils.realtime_data_populator import populate_monitoring_points_old_fields

        populated_config, population_stats = populate_monitoring_points_old_fields(
            config, room_id
        )

        # è®°å½•å¡«å……ç»Ÿè®¡ä¿¡æ¯
        success_count = population_stats.get("successful_matches", 0)
        total_count = population_stats.get("total_points", 0)
        success_rate = population_stats.get("success_rate", 0)
        
        logger.info(log_message(
            "DATA_FETCH_SUCCESS",
            "å®æ—¶æ•°æ®å¡«å……å®Œæˆ",
            room_id=room_id,
            success_count=success_count,
            total_count=total_count,
            success_rate=success_rate
        ))

        # å¦‚æœå®æ—¶æ•°æ®è·å–æˆåŠŸç‡å¾ˆä½ï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥
        if success_rate < 10:  # æˆåŠŸç‡ä½äº10%
            logger.warning(log_message(
                "DATA_FETCH_WARNING",
                "å®æ—¶æ•°æ®è·å–æˆåŠŸç‡è¿‡ä½ï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥",
                room_id=room_id,
                success_rate=success_rate
            ))
            
            # å°è¯•ä½¿ç”¨è®¾å¤‡é…ç½®ä¸­çš„é»˜è®¤å€¼æˆ–å†å²å¹³å‡å€¼
            populated_config = _populate_with_fallback_values(populated_config, room_id)

        return populated_config

    except ImportError as e:
        logger.warning(log_message(
            "DEPENDENCY_IMPORT_ERROR",
            "æ— æ³•å¯¼å…¥å®æ—¶æ•°æ®å¡«å……å™¨ï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥",
            error=str(e)
        ))
        return _populate_with_fallback_values(config, room_id)
    except Exception as e:
        logger.warning(log_message(
            "DATA_FETCH_ERROR",
            "å®æ—¶æ•°æ®å¡«å……å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥",
            error=str(e)
        ))
        return _populate_with_fallback_values(config, room_id)


def _populate_with_fallback_values(config: Dict[str, Any], room_id: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨å¤‡ç”¨ç­–ç•¥å¡«å……oldå­—æ®µ
    
    Args:
        config: ç›‘æ§ç‚¹é…ç½®
        room_id: åº“æˆ¿ç¼–å·
        
    Returns:
        å¡«å……åçš„é…ç½®
    """
    try:
        # å®šä¹‰å„ç±»å‹å‚æ•°çš„å…¸å‹å€¼ï¼ˆåŸºäºå®é™…ç”Ÿäº§ç¯å¢ƒçš„åˆç†å€¼ï¼‰
        typical_values = {
            "air_cooler": {
                "temp_set": 15.0,      # å†·é£æœºæ¸©åº¦è®¾å®šï¼Œé€šå¸¸åœ¨12-18â„ƒ
                "temp_diffset": 2.0,   # æ¸©å·®è®¾å®šï¼Œé€šå¸¸1.5-3â„ƒ
                "cyc_on_time": 10,     # å¾ªç¯å¼€å¯æ—¶é—´ï¼Œé€šå¸¸5-15åˆ†é’Ÿ
                "cyc_off_time": 10,    # å¾ªç¯å…³é—­æ—¶é—´ï¼Œé€šå¸¸5-15åˆ†é’Ÿ
                "on_off": 1,           # å†·é£æœºé€šå¸¸æ˜¯å¼€å¯çŠ¶æ€
                "cyc_on_off": 1,       # å¾ªç¯æ¨¡å¼é€šå¸¸å¼€å¯
                "air_on_off": 0,       # æ–°é£è”åŠ¨æ ¹æ®éœ€è¦
                "hum_on_off": 0        # åŠ æ¹¿è”åŠ¨æ ¹æ®éœ€è¦
            },
            "fresh_air_fan": {
                "mode": 1,             # è‡ªåŠ¨æ¨¡å¼
                "control": 1,          # CO2æ§åˆ¶
                "co2_on": 1000,        # CO2å¯åŠ¨é˜ˆå€¼ï¼Œé€šå¸¸800-1200ppm
                "co2_off": 800,        # CO2åœæ­¢é˜ˆå€¼ï¼Œé€šå¸¸600-1000ppm
                "on": 10,              # æ—¶æ§å¼€å¯æ—¶é—´ï¼Œé€šå¸¸5-15åˆ†é’Ÿ
                "off": 10              # æ—¶æ§å…³é—­æ—¶é—´ï¼Œé€šå¸¸5-15åˆ†é’Ÿ
            },
            "humidifier": {
                "mode": 1,             # è‡ªåŠ¨æ¨¡å¼
                "on": 85,              # åŠ æ¹¿å¼€å¯é˜ˆå€¼ï¼Œé€šå¸¸80-90%
                "off": 90              # åŠ æ¹¿åœæ­¢é˜ˆå€¼ï¼Œé€šå¸¸85-95%
            },
            "grow_light": {
                "model": 1,            # è‡ªåŠ¨æ¨¡å¼
                "on_mset": 60,         # å¼€å¯æ—¶é•¿ï¼Œé€šå¸¸30-120åˆ†é’Ÿ
                "off_mset": 60,        # å…³é—­æ—¶é•¿ï¼Œé€šå¸¸30-120åˆ†é’Ÿ
                "on_off1": 1,          # 1å·è¡¥å…‰ç¯é€šå¸¸å¼€å¯
                "on_off2": 1,          # 2å·è¡¥å…‰ç¯é€šå¸¸å¼€å¯
                "on_off3": 0,          # 3å·è¡¥å…‰ç¯æ ¹æ®éœ€è¦
                "on_off4": 0,          # 4å·è¡¥å…‰ç¯æ ¹æ®éœ€è¦
                "choose1": 0,          # 1å·å…‰æºé€‰æ‹©ç™½å…‰
                "choose2": 0,          # 2å·å…‰æºé€‰æ‹©ç™½å…‰
                "choose3": 0,          # 3å·å…‰æºé€‰æ‹©ç™½å…‰
                "choose4": 0           # 4å·å…‰æºé€‰æ‹©ç™½å…‰
            }
        }
        
        devices = config.get("devices", {})
        filled_count = 0
        
        for device_type, device_list in devices.items():
            device_typical_values = typical_values.get(device_type, {})
            
            for device in device_list:
                for point in device.get("point_list", []):
                    point_alias = point.get("point_alias")
                    
                    # å¦‚æœoldå­—æ®µä¸ºç©ºæˆ–ä¸º0ï¼Œä½¿ç”¨å…¸å‹å€¼
                    if point.get("old") is None or point.get("old") == 0:
                        typical_value = device_typical_values.get(point_alias)
                        
                        if typical_value is not None:
                            point["old"] = typical_value
                            filled_count += 1
                            
                            logger.debug(log_message(
                                "DATA_FETCH_FALLBACK",
                                f"ä½¿ç”¨å…¸å‹å€¼å¡«å…… {device_type}.{point_alias}",
                                value=typical_value
                            ))
                        else:
                            # ä½¿ç”¨ç±»å‹é»˜è®¤å€¼
                            default_value = _get_default_value_by_type(point.get("change_type"))
                            point["old"] = default_value
                            filled_count += 1
        
        logger.info(log_message(
            "DATA_FETCH_FALLBACK",
            "ä½¿ç”¨å¤‡ç”¨ç­–ç•¥å¡«å……å®Œæˆ",
            room_id=room_id,
            filled_count=filled_count
        ))
        
        return config
        
    except Exception as e:
        logger.error(log_message(
            "DATA_FETCH_FALLBACK",
            "å¤‡ç”¨ç­–ç•¥å¡«å……å¤±è´¥",
            error=str(e)
        ))
        return config


def _validate_and_update_change_flags(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    éªŒè¯å¹¶æ›´æ–°ç›‘æ§ç‚¹é…ç½®ä¸­çš„changeå­—æ®µå’Œlevelå­—æ®µ
    
    åœ¨å®æ—¶æ•°æ®å¡«å……å®Œæˆåï¼Œé‡æ–°æ£€æŸ¥oldå’Œnewå€¼çš„å·®å¼‚ï¼Œ
    ç¡®ä¿changeå­—æ®µæ­£ç¡®åæ˜ æ˜¯å¦éœ€è¦å‚æ•°è°ƒæ•´ã€‚
    
    Args:
        config: ç›‘æ§ç‚¹é…ç½®
        
    Returns:
        æ›´æ–°åçš„é…ç½®
    """
    try:
        devices = config.get("devices", {})
        updated_count = 0
        
        for device_type, device_list in devices.items():
            for device in device_list:
                for point in device.get("point_list", []):
                    old_value = point.get("old")
                    new_value = point.get("new")
                    change_type = point.get("change_type")
                    threshold = point.get("threshold")
                    point_alias = point.get("point_alias")
                    
                    # åŸå§‹changeçŠ¶æ€
                    original_change = point.get("change", False)
                    
                    # é‡æ–°è®¡ç®—æ˜¯å¦éœ€è¦è°ƒæ•´
                    should_change = _should_change_parameter(
                        old_value=old_value,
                        new_value=new_value,
                        action="adjust" if original_change else "maintain",
                        change_type=change_type,
                        threshold=threshold
                    )
                    
                    # æ›´æ–°changeå­—æ®µ
                    if should_change != original_change:
                        point["change"] = should_change
                        updated_count += 1
                        
                        logger.debug(log_message(
                            "OUTPUT_FORMAT_CONVERSION",
                            f"æ›´æ–°changeæ ‡å¿— {device_type}.{point_alias}",
                            old=old_value,
                            new=new_value,
                            original_change=original_change,
                            updated_change=should_change
                        ))
                    
                    # é‡æ–°è®¡ç®—ä¼˜å…ˆçº§
                    original_level = point.get("level", "medium")
                    updated_level = _determine_priority_level(
                        change_required=should_change,
                        priority=original_level,
                        point_alias=point_alias,
                        device_type=device_type
                    )
                    
                    if updated_level != original_level:
                        point["level"] = updated_level
                        logger.debug(log_message(
                            "OUTPUT_FORMAT_CONVERSION",
                            f"æ›´æ–°ä¼˜å…ˆçº§ {device_type}.{point_alias}",
                            original_level=original_level,
                            updated_level=updated_level
                        ))
        
        logger.info(log_message(
            "OUTPUT_FORMAT_CONVERSION",
            "éªŒè¯å¹¶æ›´æ–°changeå­—æ®µå®Œæˆ",
            room_id=config.get("room_id"),
            updated_count=updated_count
        ))
        
        return config
        
    except Exception as e:
        logger.error(log_message(
            "OUTPUT_FORMAT_CONVERSION",
            "éªŒè¯changeå­—æ®µæ—¶å‘ç”Ÿé”™è¯¯",
            error=str(e)
        ))
        return config




# ===================== æ–‡ä»¶ä¿å­˜ =====================

def save_enhanced_json_output(result: EnhancedDecisionAnalysisResult,
                              output_path: Path,
                              output_format: str = "both") -> None:
    """
    ä¿å­˜å¢å¼ºå†³ç­–è¾“å‡ºåˆ°JSONæ–‡ä»¶ã€‚

    Args:
        result: å¢å¼ºå†³ç­–åˆ†æç»“æœ
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_format: è¾“å‡ºæ ¼å¼ ("enhanced", "monitoring", "both")

    Raises:
        Exception: æ–‡ä»¶ä¿å­˜å¤±è´¥
    """
    logger.debug(log_message(
        "FILE_SAVE_START",
        "å¼€å§‹ä¿å­˜å¢å¼ºå†³ç­–è¾“å‡ºåˆ°æ–‡ä»¶",
        path=str(output_path),
        format=output_format
    ))

    if not result.enhanced_decision_output:
        raise ValueError("æ²¡æœ‰å¯ä¿å­˜çš„å¢å¼ºå†³ç­–è¾“å‡ºæ•°æ®")

    # å‡†å¤‡è¾“å‡ºæ•°æ®
    output_data = _prepare_output_data(result, output_format)

    # å†™å…¥æ–‡ä»¶ï¼Œä½¿ç”¨ç¾åŒ–æ ¼å¼
    try:
        logger.debug(log_message(
            "JSON_SERIALIZATION",
            "å¼€å§‹å†™å…¥JSONæ•°æ®åˆ°æ–‡ä»¶",
            path=str(output_path)
        ))

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2,
                      default=str)

        file_size = output_path.stat().st_size if output_path.exists() else 0
        logger.info(log_message(
            "FILE_SAVE_SUCCESS",
            "å¢å¼ºå†³ç­–ç»“æœä¿å­˜æˆåŠŸ",
            path=str(output_path),
            format=output_format,
            size=f"{file_size}å­—èŠ‚"
        ))

        # å¦‚æœæ ¼å¼ä¸ºbothï¼Œè¿˜è¦ä¿å­˜ç›‘æ§ç‚¹é…ç½®åˆ°å•ç‹¬æ–‡ä»¶
        if output_format == "both" and "monitoring_points" in output_data:
            monitoring_points_path = (
                output_path.parent /
                f"monitoring_points_{output_path.stem}.json"
            )
            try:
                logger.debug(log_message(
                    "FILE_SAVE_START",
                    "ä¿å­˜ç›‘æ§ç‚¹é…ç½®åˆ°å•ç‹¬æ–‡ä»¶",
                    path=str(monitoring_points_path)
                ))

                with open(monitoring_points_path, 'w', encoding='utf-8') as f:
                    json.dump(output_data["monitoring_points"], f,
                              ensure_ascii=False, indent=2, default=str)

                mp_file_size = (
                    monitoring_points_path.stat().st_size
                    if monitoring_points_path.exists() else 0
                )
                logger.info(log_message(
                    "FILE_SAVE_SUCCESS",
                    "ç›‘æ§ç‚¹é…ç½®æ–‡ä»¶ä¿å­˜æˆåŠŸ",
                    path=str(monitoring_points_path),
                    size=f"{mp_file_size}å­—èŠ‚"
                ))
            except Exception as e:
                logger.warning(log_message(
                    "FILE_SAVE_ERROR",
                    "ç›‘æ§ç‚¹é…ç½®æ–‡ä»¶ä¿å­˜å¤±è´¥",
                    error=str(e)
                ))

    except Exception as e:
        error_msg = (
            f"ä¿å­˜å¢å¼ºå†³ç­–ç»“æœåˆ° {output_path} å¤±è´¥: {str(e)}"
        )
        logger.error(log_message("FILE_SAVE_ERROR", error_msg))
        raise


def _convert_enhanced_output_to_json(enhanced_output: Any) -> Dict[str, Any]:
    """
    Convert enhanced decision output to clean JSON format, removing string representations
    and image quality scores.
    
    Args:
        enhanced_output: Enhanced decision output object
        
    Returns:
        Clean JSON dictionary
    """
    if not enhanced_output:
        return {}
    
    # If it's already a dict, return it
    if isinstance(enhanced_output, dict):
        return enhanced_output
    
    # Convert object to dict, handling dataclass objects
    try:
        import dataclasses
        if dataclasses.is_dataclass(enhanced_output):
            result = dataclasses.asdict(enhanced_output)
        else:
            # Try to get attributes
            result = {}
            for attr in dir(enhanced_output):
                if not attr.startswith('_'):
                    try:
                        value = getattr(enhanced_output, attr)
                        if not callable(value):
                            if dataclasses.is_dataclass(value):
                                result[attr] = dataclasses.asdict(value)
                            elif hasattr(value, '__dict__'):
                                result[attr] = value.__dict__
                            else:
                                result[attr] = value
                    except:
                        continue
        
        # Clean up the result - remove image quality scores and other unnecessary data
        if 'multi_image_analysis' in result:
            multi_img = result['multi_image_analysis']
            if isinstance(multi_img, dict):
                # Keep only essential multi-image analysis data
                cleaned_multi_img = {
                    'total_images_analyzed': multi_img.get('total_images_analyzed', 0),
                    'confidence_score': multi_img.get('confidence_score', 0.0),
                    'view_consistency': multi_img.get('view_consistency', 'unknown'),
                    'aggregation_method': multi_img.get('aggregation_method', 'single_image')
                }
                # Remove image quality scores and detailed observations
                result['multi_image_analysis'] = cleaned_multi_img
        
        return result
        
    except Exception as e:
        logger.warning(f"Failed to convert enhanced output to JSON: {e}")
        return {"error": "Failed to convert enhanced output", "raw_type": str(type(enhanced_output))}


def _prepare_output_data(result: EnhancedDecisionAnalysisResult,
                         output_format: str) -> Dict[str, Any]:
    """
    å‡†å¤‡è¾“å‡ºæ•°æ®ã€‚

    Args:
        result: å¢å¼ºå†³ç­–åˆ†æç»“æœ
        output_format: è¾“å‡ºæ ¼å¼

    Returns:
        å‡†å¤‡å¥½çš„è¾“å‡ºæ•°æ®
    """
    if output_format == "enhanced":
        # Convert enhanced decision output to clean JSON format
        return _convert_enhanced_output_to_json(result.enhanced_decision_output)

    elif output_format == "monitoring":
        return convert_to_monitoring_points_format(result, result.room_id)

    elif output_format == "both":
        monitoring_points = convert_to_monitoring_points_format(
            result, result.room_id
        )
        return {
            "enhanced_decision": _convert_enhanced_output_to_json(result.enhanced_decision_output),
            "monitoring_points": monitoring_points,
            "metadata": {
                "room_id": result.room_id,
                "analysis_datetime": (
                    result.analysis_datetime.isoformat()
                    if result.analysis_datetime else None
                ),
                "processing_time": result.processing_time,
                "generated_at": datetime.now().isoformat()
            }
        }

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {output_format}")


# ===================== æ–‡ä»¶åç”Ÿæˆ =====================

def generate_enhanced_output_filename(room_id: str,
                                      analysis_datetime: datetime,
                                      output_dir: Optional[Path] = None
                                      ) -> Path:
    """
    ç”Ÿæˆå¢å¼ºå†³ç­–è¾“å‡ºæ–‡ä»¶åã€‚

    Args:
        room_id: åº“æˆ¿ç¼–å·
        analysis_datetime: åˆ†ææ—¶é—´
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹

    Returns:
        å®Œæ•´çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„

    Raises:
        Exception: æ–‡ä»¶åç”Ÿæˆå¤±è´¥
    """
    logger.debug(log_message(
        "OUTPUT_PATH_GENERATION",
        "å¼€å§‹ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å",
        room_id=room_id,
        datetime=analysis_datetime
    ))

    try:
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        base_dir = Path(__file__).parent.parent.parent

        if output_dir is None:
            output_dir = base_dir / "output"
            logger.debug(log_message(
                "OUTPUT_PATH_GENERATION",
                "ä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•",
                path=str(output_dir)
            ))
        else:
            logger.debug(log_message(
                "OUTPUT_PATH_GENERATION",
                "ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºç›®å½•",
                path=str(output_dir)
            ))

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir.mkdir(parents=True, exist_ok=True)
        logger.debug(log_message(
            "OUTPUT_PATH_GENERATION",
            "è¾“å‡ºç›®å½•å·²ç¡®ä¿å­˜åœ¨",
            path=str(output_dir)
        ))

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = analysis_datetime.strftime("%Y%m%d_%H%M%S")
        filename = f"enhanced_decision_analysis_{room_id}_{timestamp}.json"
        full_path = output_dir / filename

        logger.info(log_message(
            "OUTPUT_PATH_GENERATION",
            "è¾“å‡ºæ–‡ä»¶åç”ŸæˆæˆåŠŸ",
            room_id=room_id,
            filename=filename,
            path=str(full_path)
        ))

        return full_path

    except Exception as e:
        error_msg = f"ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åå¤±è´¥: {str(e)}"
        logger.error(log_message("OUTPUT_PATH_GENERATION", error_msg))
        raise


# ===================== æ ¸å¿ƒæ‰§è¡Œå‡½æ•° =====================

def execute_enhanced_decision_analysis(
    room_id: str,
    analysis_datetime: Optional[datetime] = None,
    output_file: Optional[Union[str, Path]] = None,
    verbose: bool = False,
    output_format: str = "monitoring"
) -> EnhancedDecisionAnalysisResult:
    """
    æ‰§è¡Œå¢å¼ºå†³ç­–åˆ†æçš„æ ¸å¿ƒå‡½æ•°ã€‚

    Args:
        room_id: åº“æˆ¿ç¼–å·
        analysis_datetime: åˆ†ææ—¶é—´ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¶é—´
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆ
        verbose: æ˜¯å¦å¯ç”¨è¯¦ç»†è¾“å‡º
        output_format: è¾“å‡ºæ ¼å¼ ("enhanced", "monitoring", "both")

    Returns:
        å¢å¼ºå†³ç­–åˆ†æç»“æœ

    Raises:
        ValueError: å‚æ•°éªŒè¯å¤±è´¥
        ImportError: ä¾èµ–å¯¼å…¥å¤±è´¥
        Exception: å…¶ä»–æ‰§è¡Œé”™è¯¯
    """
    result = EnhancedDecisionAnalysisResult()
    start_time = time.time()

    logger.info(log_message(
        "BUSINESS_FLOW_START",
        "å¼€å§‹æ‰§è¡Œå¢å¼ºå†³ç­–åˆ†æ",
        room_id=room_id
    ))
    logger.debug(log_message(
        "PARAM_VALIDATION_START",
        "è¾“å…¥å‚æ•°éªŒè¯",
        room_id=room_id,
        analysis_datetime=analysis_datetime,
        output_file=output_file,
        verbose=verbose,
        output_format=output_format
    ))

    # è®°å½•åˆå§‹å†…å­˜ä½¿ç”¨æƒ…å†µ
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    logger.info(log_message(
        "PERFORMANCE_MEMORY_USAGE",
        "åˆå§‹å†…å­˜ä½¿ç”¨æƒ…å†µ",
        rss_mb=f"{memory_info.rss / 1024 / 1024:.2f}",
        vms_mb=f"{memory_info.vms / 1024 / 1024:.2f}"
    ))

    try:
        # è®¾ç½®é»˜è®¤åˆ†ææ—¶é—´
        if analysis_datetime is None:
            analysis_datetime = datetime.now()
            logger.debug(log_message(
                "PARAM_VALIDATION_SUCCESS",
                "ä½¿ç”¨å½“å‰åˆ†ææ—¶é—´",
                analysis_time=analysis_datetime
            ))

        result.room_id = room_id
        result.analysis_datetime = analysis_datetime

        # éªŒè¯æˆ¿é—´ID
        logger.info(log_message(
            "ROOM_ID_VALIDATION",
            "å¼€å§‹éªŒè¯åº“æˆ¿ID",
            room_id=room_id
        ))

        if room_id not in MUSHROOM_ROOM_IDS:
            result.error_message = (
                f"æ— æ•ˆçš„åº“æˆ¿ID: {room_id}. "
                f"å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: {MUSHROOM_ROOM_IDS}"
            )
            result.processing_time = time.time() - start_time
            logger.error(log_message(
                "PARAM_VALIDATION_ERROR",
                "åº“æˆ¿IDéªŒè¯å¤±è´¥",
                room_id=room_id,
                valid_ids=MUSHROOM_ROOM_IDS
            ))
            return result

        logger.info(log_message(
            "PARAM_VALIDATION_SUCCESS",
            "åº“æˆ¿IDéªŒè¯é€šè¿‡",
            room_id=room_id
        ))

        # å¯¼å…¥ä¾èµ–
        logger.debug(log_message(
            "DEPENDENCY_IMPORT_START", "å¼€å§‹å¯¼å…¥ç³»ç»Ÿä¾èµ–"
        ))

        from global_const.global_const import (
            BASE_DIR,
            settings,
            static_settings,
            pgsql_engine
        )
        from decision_analysis.decision_analyzer import DecisionAnalyzer

        logger.debug(log_message("DEPENDENCY_IMPORT_SUCCESS", "ç³»ç»Ÿä¾èµ–å¯¼å…¥æˆåŠŸ"))

        # è·å–æ¨¡æ¿è·¯å¾„
        template_path = BASE_DIR / "configs" / "decision_prompt.jinja"
        logger.debug(log_message(
            "TEMPLATE_VALIDATION",
            "æ£€æŸ¥å†³ç­–æ¨¡æ¿æ–‡ä»¶",
            path=str(template_path)
        ))

        if not template_path.exists():
            result.error_message = f"æ¨¡æ¿æ–‡ä»¶æœªæ‰¾åˆ°: {template_path}"
            result.processing_time = time.time() - start_time
            logger.error(log_message("TEMPLATE_VALIDATION", result.error_message))
            return result

        logger.info(log_message(
            "TEMPLATE_VALIDATION",
            "å†³ç­–æ¨¡æ¿æ–‡ä»¶éªŒè¯æˆåŠŸ",
            path=str(template_path)
        ))

        # åˆå§‹åŒ–DecisionAnalyzer
        logger.info(log_message(
            "ANALYZER_INIT_START",
            "å¼€å§‹åˆå§‹åŒ–å†³ç­–åˆ†æå™¨",
            template="decision_prompt.jinja"
        ))

        analyzer = DecisionAnalyzer(
            db_engine=pgsql_engine,
            settings=settings,
            static_config=static_settings,
            template_path=str(template_path)
        )

        logger.info(log_message("ANALYZER_INIT_SUCCESS", "å†³ç­–åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ"))
        logger.debug(log_message(
            "DB_CONNECTION_CHECK",
            "æ•°æ®åº“å¼•æ“é…ç½®å®Œæˆ",
            engine_type=type(pgsql_engine).__name__
        ))

        # æ‰§è¡Œå¢å¼ºåˆ†æ
        analysis_start = time.time()
        logger.info(log_message(
            "BUSINESS_FLOW_CHECKPOINT",
            "å¼€å§‹æ‰§è¡Œå¢å¼ºå†³ç­–åˆ†ææ ¸å¿ƒæµç¨‹",
            room_id=room_id,
            analysis_time=analysis_datetime
        ))

        # è®°å½•åˆ†æå‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        logger.info(log_message(
            "BUSINESS_FLOW_CHECKPOINT",
            "åˆ†æä¸Šä¸‹æ–‡ä¿¡æ¯è®°å½•",
            room_id=room_id,
            analysis_time=analysis_datetime,
            template_name="decision_prompt.jinja"
        ))

        enhanced_decision_output = analyzer.analyze_enhanced(
            room_id=room_id,
            analysis_datetime=analysis_datetime
        )

        analysis_duration = time.time() - analysis_start
        logger.info(log_message(
            "BUSINESS_FLOW_CHECKPOINT",
            "å¢å¼ºå†³ç­–åˆ†ææ ¸å¿ƒæµç¨‹å®Œæˆ",
            room_id=room_id,
            processing_time=analysis_duration
        ))

        result.enhanced_decision_output = enhanced_decision_output
        result.metadata = {
            "data_sources": enhanced_decision_output.metadata.data_sources,
            "similar_cases_count": enhanced_decision_output.metadata.similar_cases_count,
            "avg_similarity_score": enhanced_decision_output.metadata.avg_similarity_score,
            "llm_model": enhanced_decision_output.metadata.llm_model,
            "llm_response_time": enhanced_decision_output.metadata.llm_response_time,
            "total_processing_time": enhanced_decision_output.metadata.total_processing_time,
            "warnings": enhanced_decision_output.metadata.warnings,
            "errors": enhanced_decision_output.metadata.errors,
            "multi_image_count": getattr(enhanced_decision_output.metadata, "multi_image_count", 0),
            "image_aggregation_method": getattr(
                enhanced_decision_output.metadata, "image_aggregation_method", "single_image"
            ),
            "enhanced_format": True,
        }

        # è®°å½•å¢å¼ºåŠŸèƒ½ä½¿ç”¨æƒ…å†µ
        enhanced_features = [
            "multi_image_aggregation",
            "structured_parameter_adjustments",
            "risk_assessment",
            "enhanced_llm_prompting"
        ]

        logger.debug(log_message(
            "BUSINESS_FLOW_CHECKPOINT",
            "å¢å¼ºåŠŸèƒ½ä½¿ç”¨è®°å½•",
            features=enhanced_features,
            multi_image_count=result.metadata.get("multi_image_count", 0)
        ))

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if output_file:
            output_path = (
                Path(output_file) if isinstance(output_file, str)
                else output_file
            )
            logger.debug(log_message(
                "OUTPUT_PATH_GENERATION",
                "ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶è·¯å¾„",
                path=str(output_path)
            ))
        else:
            output_path = generate_enhanced_output_filename(
                room_id, analysis_datetime
            )
            logger.debug(log_message(
                "OUTPUT_PATH_GENERATION",
                "è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„",
                path=str(output_path)
            ))

        # ä¿å­˜ç»“æœ
        save_start = time.time()
        save_enhanced_json_output(result, output_path, output_format)
        save_duration = time.time() - save_start
        logger.debug(log_message(
            "PERFORMANCE_EXECUTION_TIME",
            "JSONæ–‡ä»¶ä¿å­˜å®Œæˆ",
            processing_time=save_duration
        ))

        result.output_file = output_path
        result.success = True
        result.processing_time = time.time() - start_time

        # è®°å½•æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡
        final_memory = process.memory_info()
        memory_delta = final_memory.rss - memory_info.rss

        performance_summary = {
            "total_time": result.processing_time,
            "analysis_time": analysis_duration,
            "save_time": save_duration,
            "memory_delta_mb": memory_delta / 1024 / 1024,
            "final_memory_mb": final_memory.rss / 1024 / 1024
        }

        logger.debug(log_message(
            "PERFORMANCE_EXECUTION_TIME",
            "æ€§èƒ½æŒ‡æ ‡æ€»ç»“",
            **performance_summary
        ))

        logger.info(log_message(
            "FINAL_SUMMARY",
            "å¢å¼ºå†³ç­–åˆ†ææ‰§è¡ŒæˆåŠŸ",
            room_id=room_id,
            processing_time=result.processing_time,
            output_file=str(result.output_file)
        ))

        return result

    except Exception as e:
        result.error_message = f"å¢å¼ºå†³ç­–åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}"
        result.processing_time = time.time() - start_time
        logger.error(log_message(
            "BUSINESS_FLOW_COMPLETE",
            "å¢å¼ºå†³ç­–åˆ†ææ‰§è¡Œå¤±è´¥",
            room_id=room_id,
            error=str(e),
            processing_time=result.processing_time
        ))
        return result


# ===================== CLIæ¥å£ =====================

def create_argument_parser() -> argparse.ArgumentParser:
    """
    åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨ã€‚

    Returns:
        é…ç½®å¥½çš„ArgumentParserå®ä¾‹
    """
    parser = argparse.ArgumentParser(
        description="Run enhanced decision analysis for mushroom growing rooms",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Enhanced Features:
  â€¢ Multi-image aggregation and analysis
  â€¢ Structured parameter adjustments with actions (maintain/adjust/monitor)
  â€¢ Risk assessments and priority levels
  â€¢ Enhanced LLM prompting and parsing
  â€¢ Comprehensive validation and fallback mechanisms

Examples:
  # Analyze room 611 at current time with enhanced features (both formats)
  python scripts/run_enhanced_decision_analysis.py --room-id 611
  
  # Analyze room 611 at specific datetime
  python scripts/run_enhanced_decision_analysis.py --room-id 611 \\
      --datetime "2024-01-15 10:00:00"
  
  # Save results to custom file
  python scripts/run_enhanced_decision_analysis.py --room-id 611 \\
      --output my_enhanced_results.json
  
  # Output only monitoring points config format
  python scripts/run_enhanced_decision_analysis.py --room-id 611 \\
      --format monitoring
  
  # Output only enhanced analysis format
  python scripts/run_enhanced_decision_analysis.py --room-id 611 \\
      --format enhanced
  
  # Verbose output with debug logs
  python scripts/run_enhanced_decision_analysis.py --room-id 611 --verbose
        """
    )

    parser.add_argument(
        "--room-id",
        type=str,
        choices=MUSHROOM_ROOM_IDS,
        default="607",
        help="Room ID (607, 608, 611, or 612)"
    )

    parser.add_argument(
        "--datetime",
        type=str,
        help=(
            "Analysis datetime in format 'YYYY-MM-DD HH:MM:SS' "
            "(default: current time)"
        )
    )

    parser.add_argument(
        "--output",
        type=str,
        help=(
            "Output JSON file path "
            "(default: enhanced_decision_analysis_<room_id>_<timestamp>.json)"
        )
    )

    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose output (DEBUG level logs)"
    )

    parser.add_argument(
        "--format",
        type=str,
        choices=OUTPUT_FORMATS,
        default="monitoring",
        help=(
            "Output format: 'enhanced' (original format), "
            "'monitoring' (monitoring points config format), "
            "or 'both' (default: monitoring)"
        )
    )

    parser.add_argument(
        "--no-console",
        action="store_true",
        help="Skip console output, only save to JSON file"
    )

    return parser


def main() -> int:
    """
    ä¸»CLIå…¥å£ç‚¹ã€‚

    Returns:
        é€€å‡ºç ï¼š0è¡¨ç¤ºæˆåŠŸï¼Œ1è¡¨ç¤ºå¤±è´¥
    """
    # æ—¥å¿—è®¾ç½®å·²åœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ–
    pass

    logger.info("=" * 80)
    logger.info("Enhanced Decision Analysis CLI")
    logger.info("=" * 80)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = create_argument_parser()
    args = parser.parse_args()

    # è®°å½•CLIå¯åŠ¨ä¸Šä¸‹æ–‡
    logger.info(log_message(
        "SYSTEM_INIT_START",
        "CLIå¯åŠ¨",
        room_id=args.room_id,
        datetime=args.datetime,
        output=args.output,
        output_format=args.format,
        verbose=args.verbose,
        no_console=args.no_console
    ))

    # Parse datetime
    try:
        logger.debug(log_message(
            "DATETIME_PARSING",
            "è§£ææ—¥æœŸæ—¶é—´å‚æ•°",
            input=args.datetime
        ))
        analysis_datetime = parse_datetime(args.datetime)
        logger.info(log_message(
            "PARAM_VALIDATION_SUCCESS",
            "CLIå‚æ•°è§£ææˆåŠŸ",
            room_id=args.room_id,
            analysis_time=analysis_datetime
        ))
    except ValueError as e:
        logger.error(log_message(
            "PARAM_VALIDATION_ERROR",
            "æ—¥æœŸæ—¶é—´è§£æå¤±è´¥",
            error=str(e)
        ))
        return 1

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logger.remove()
        logger.add(sys.stderr, level="DEBUG")

    # æ‰§è¡Œå¢å¼ºå†³ç­–åˆ†æ
    try:
        logger.info(log_message(
            "BUSINESS_FLOW_START",
            "ä»CLIæ‰§è¡Œå¢å¼ºå†³ç­–åˆ†æ"
        ))

        result = execute_enhanced_decision_analysis(
            room_id=args.room_id,
            analysis_datetime=analysis_datetime,
            output_file=args.output,
            verbose=args.verbose,
            output_format=args.format
        )

        if result.success:
            logger.info(log_message(
                "FINAL_SUMMARY",
                "å¢å¼ºå†³ç­–åˆ†ææ‰§è¡ŒæˆåŠŸ",
                room_id=result.room_id,
                processing_time=result.processing_time
            ))

            # æ§åˆ¶å°è¾“å‡ºï¼ˆé™¤éç¦ç”¨ï¼‰
            if not args.no_console:
                console_output = format_enhanced_console_output(result)
                print(console_output)

            logger.info(log_message(
                "FILE_SAVE_SUCCESS",
                "è¾“å‡ºæ–‡ä»¶",
                path=str(result.output_file.absolute())
            ))

        else:
            logger.error(log_message(
                "FINAL_SUMMARY",
                "å¢å¼ºå†³ç­–åˆ†ææ‰§è¡Œå¤±è´¥",
                room_id=args.room_id,
                error=result.error_message
            ))
            print(f"âŒ é”™è¯¯: {result.error_message}")

    except Exception as e:
        logger.error(log_message(
            "SYSTEM_INIT_ERROR",
            "CLIæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸé”™è¯¯",
            error=str(e)
        ))
        print(f"âŒ æœªé¢„æœŸé”™è¯¯: {str(e)}")
        return 1

    logger.info("=" * 80)

    # æ ¹æ®çŠ¶æ€è¿”å›é€€å‡ºç 
    return 0 if result.success else 1


if __name__ == "__main__":
    sys.exit(main())