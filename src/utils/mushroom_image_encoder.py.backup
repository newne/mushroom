"""
è˜‘è‡å›¾åƒç¼–ç å™¨
ä½¿ç”¨CLIPæ¨¡å‹å¯¹MinIOä¸­çš„è˜‘è‡å›¾åƒè¿›è¡Œç¼–ç ï¼Œè§£ææ—¶é—´ä¿¡æ¯ï¼Œå¹¶è·å–å¯¹åº”çš„ç¯å¢ƒå‚æ•°
é›†æˆLLaMAæ¨¡å‹è·å–è˜‘è‡ç”Ÿé•¿æƒ…å†µæè¿°
"""

import base64
import io
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Any

import numpy as np
import requests
import torch
from PIL import Image
from loguru import logger
from sqlalchemy.orm import sessionmaker
from transformers import CLIPProcessor, CLIPModel

from global_const.global_const import pgsql_engine, settings
from utils.create_table import MushroomImageEmbedding
from utils.env_data_processor import create_env_data_processor
from utils.minio_client import create_minio_client
from utils.mushroom_image_processor import create_mushroom_processor, MushroomImageInfo


class MushroomImageEncoder:
    """è˜‘è‡å›¾åƒç¼–ç å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¼–ç å™¨"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"Detected device: {self.device}")
        
        # åˆå§‹åŒ–CLIPæ¨¡å‹
        self._init_clip_model()
        
        # åˆå§‹åŒ–MinIOå®¢æˆ·ç«¯å’Œå¤„ç†å™¨
        self.minio_client = create_minio_client()
        self.processor = create_mushroom_processor()
        
        # åˆå§‹åŒ–æ•°æ®åº“ä¼šè¯
        self.Session = sessionmaker(bind=pgsql_engine)
        
        # åˆå§‹åŒ–ç¯å¢ƒæ•°æ®å¤„ç†å™¨
        self._init_env_processor()
        
        # åˆå§‹åŒ–LLaMAå®¢æˆ·ç«¯
        self._init_llama_client()
        
        # åº“æˆ¿å·æ˜ å°„ï¼šMinIOä¸­çš„åº“æˆ¿å· -> ç¯å¢ƒé…ç½®ä¸­çš„åº“æˆ¿å·
        self.room_id_mapping = {
            '7': '607',   # MinIOä¸­çš„7å¯¹åº”ç¯å¢ƒé…ç½®ä¸­çš„607
            '8': '608',   # MinIOä¸­çš„8å¯¹åº”ç¯å¢ƒé…ç½®ä¸­çš„608
        }
        
        logger.info("Mushroom image encoder initialized successfully")
    
    def _map_room_id(self, room_id: str) -> str:
        """
        æ˜ å°„åº“æˆ¿å·ï¼šå°†MinIOä¸­çš„åº“æˆ¿å·æ˜ å°„åˆ°ç¯å¢ƒé…ç½®ä¸­çš„åº“æˆ¿å·
        
        Args:
            room_id: MinIOä¸­çš„åº“æˆ¿å·
            
        Returns:
            ç¯å¢ƒé…ç½®ä¸­å¯¹åº”çš„åº“æˆ¿å·
        """
        mapped_id = self.room_id_mapping.get(room_id, room_id)
        if mapped_id != room_id:
            logger.debug(f"Mapped room ID: {room_id} -> {mapped_id}")
        return mapped_id
    
    def _init_clip_model(self):
        """åˆå§‹åŒ–CLIPæ¨¡å‹"""
        # æ£€æŸ¥æœ¬åœ°æ¨¡å‹è·¯å¾„
        # åœ¨å®¹å™¨ä¸­ï¼Œsrcç›®å½•å†…å®¹è¢«å¤åˆ¶åˆ°/appï¼ŒmodelsæŒ‚è½½åˆ°/models
        # åœ¨å¼€å‘ç¯å¢ƒä¸­ï¼Œä¿æŒåŸæœ‰çš„ç›¸å¯¹è·¯å¾„è®¡ç®—
        
        # é¦–å…ˆæ£€æŸ¥å®¹å™¨ç¯å¢ƒçš„è·¯å¾„
        container_model_path = Path('/models/clip-vit-base-patch32')
        
        # ç„¶åæ£€æŸ¥å¼€å‘ç¯å¢ƒçš„è·¯å¾„
        local_model_path = Path(__file__).parent.parent.parent / 'models' / 'clip-vit-base-patch32'
        
        if container_model_path.exists():
            model_name = str(container_model_path)
            logger.info(f"Loading model from container path: {model_name}")
        elif local_model_path.exists():
            model_name = str(local_model_path)
            logger.info(f"Loading model from local path: {model_name}")
        else:
            model_name = 'openai/clip-vit-base-patch32'
            logger.info(f"Loading model from HuggingFace: {model_name}")
        
        logger.info(f"Loading CLIP model: {model_name}")
        self.clip_processor = CLIPProcessor.from_pretrained(model_name)
        self.clip_model = CLIPModel.from_pretrained(model_name).to(self.device)
        self.clip_model.eval()
        logger.info(f"CLIP model loaded successfully on device: {self.device}")
    
    def _init_env_processor(self):
        """åˆå§‹åŒ–ç¯å¢ƒæ•°æ®å¤„ç†å™¨"""
        try:
            self.env_processor = create_env_data_processor()
            logger.info("Environment data processor initialized successfully")
        except Exception as e:
            logger.warning(f"Failed to initialize environment data processor: {e}")
            self.env_processor = None
    
    def _init_llama_client(self):
        """åˆå§‹åŒ–LLaMAå®¢æˆ·ç«¯"""
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨LLaMA
            if hasattr(settings.llama, 'enabled') and not settings.llama.enabled:
                logger.info("LLaMA is disabled in configuration")
                self.llama_client = False
                return
                
            # æ ‡è®°LLaMAå®¢æˆ·ç«¯å¯ç”¨
            self.llama_client = True
            logger.info("LLaMA client initialized successfully")
        except Exception as e:
            logger.warning(f"Failed to initialize LLaMA client: {e}")
            self.llama_client = False
    
    def _call_llama_api(self, image_data: str) -> str:
        """
        ç›´æ¥è°ƒç”¨LLaMA API
        
        Args:
            image_data: base64ç¼–ç çš„å›¾åƒæ•°æ®
            
        Returns:
            LLaMAç”Ÿæˆçš„æè¿°ï¼Œå¤±è´¥æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            payload = {
                "model": f"{settings.llama.model}",
                "messages": [
                    {
                        "role": "system",
                        "content": f"{settings.llama.mushroom_descripe_prompt}"
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ]
                    }
                ],
                "max_tokens": -1,
                "temperature": 0.7,
                "stream": False
            }

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {settings.llama.api_key}"
            }
            
            base_url = settings.llama.llama_completions.format(settings.llama.llama_host, settings.llama.llama_port)
            
            # ä»é…ç½®è·å–è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤600ç§’
            timeout = getattr(settings.llama, 'timeout', 600)
            logger.debug(f"Calling LLaMA API: {base_url} (timeout: {timeout}s)")
            
            # ä½¿ç”¨requestsç›´æ¥å‘é€è¯·æ±‚ï¼Œä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
            resp = requests.post(base_url, json=payload, headers=headers, timeout=timeout)
            
            if resp.status_code == 200:
                response_data = resp.json()
                
                # æ£€æŸ¥å“åº”æ ¼å¼
                if 'choices' not in response_data:
                    logger.error(f"LLaMA APIå“åº”æ ¼å¼é”™è¯¯: ç¼ºå°‘'choices'å­—æ®µ. å“åº”å†…å®¹: {response_data}")
                    return ""
                
                if not response_data['choices']:
                    logger.error(f"LLaMA APIå“åº”æ ¼å¼é”™è¯¯: 'choices'æ•°ç»„ä¸ºç©º. å“åº”å†…å®¹: {response_data}")
                    return ""
                
                if 'message' not in response_data['choices'][0]:
                    logger.error(f"LLaMA APIå“åº”æ ¼å¼é”™è¯¯: ç¼ºå°‘'message'å­—æ®µ. å“åº”å†…å®¹: {response_data['choices'][0]}")
                    return ""
                
                if 'content' not in response_data['choices'][0]['message']:
                    logger.error(f"LLaMA APIå“åº”æ ¼å¼é”™è¯¯: ç¼ºå°‘'content'å­—æ®µ. å“åº”å†…å®¹: {response_data['choices'][0]['message']}")
                    return ""
                
                description = response_data["choices"][0]["message"]["content"]
                logger.info(f"LLaMA APIè°ƒç”¨æˆåŠŸ, æè¿°é•¿åº¦: {len(description)}å­—ç¬¦")
                return description
            else:
                logger.error(f"LLaMA APIè¯·æ±‚å¤±è´¥ - çŠ¶æ€ç : {resp.status_code}, å“åº”: {resp.text[:500]}")
                return ""  # è¿”å›ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯é”™è¯¯ä¿¡æ¯ï¼Œé¿å…æ±¡æŸ“æè¿°
                
        except requests.exceptions.Timeout:
            timeout_val = getattr(settings.llama, 'timeout', 600)
            logger.warning(f"LLaMA APIè°ƒç”¨è¶…æ—¶ (>{timeout_val}s), è·³è¿‡LLaMAæè¿°ç”Ÿæˆ")
            return ""  # è¶…æ—¶æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œç»§ç»­ä½¿ç”¨èº«ä»½å…ƒæ•°æ®
        except requests.exceptions.ConnectionError as e:
            logger.warning(f"LLaMA APIè¿æ¥é”™è¯¯: {str(e)[:200]}, è·³è¿‡LLaMAæè¿°ç”Ÿæˆ")
            return ""
        except KeyError as e:
            logger.error(f"LLaMA APIå“åº”è§£æé”™è¯¯ - ç¼ºå°‘å­—æ®µ: {e}")
            return ""
        except json.JSONDecodeError as e:
            logger.error(f"LLaMA APIå“åº”JSONè§£æå¤±è´¥: {e}")
            return ""
        except Exception as e:
            logger.error(f"LLaMA APIè°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {str(e)[:200]}")
            return ""  # è¿”å›ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯é”™è¯¯ä¿¡æ¯
    
    def _resize_image_for_llama(self, image: Image.Image) -> Image.Image:
        """
        å°†å›¾åƒç¼©æ”¾åˆ°960x540åˆ†è¾¨ç‡ç”¨äºLLaMAå¤„ç†ï¼Œå‡å°‘è¿ç®—é‡
        
        Args:
            image: åŸå§‹PILå›¾åƒå¯¹è±¡
            
        Returns:
            ç¼©æ”¾åçš„PILå›¾åƒå¯¹è±¡
        """
        try:
            # ç›®æ ‡åˆ†è¾¨ç‡ï¼šçŸ­è¾¹960ï¼Œé•¿è¾¹æŒ‰æ¯”ä¾‹ç¼©æ”¾
            original_width, original_height = image.size
            
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä½¿çŸ­è¾¹ä¸º960
            if original_width < original_height:
                # å®½åº¦æ˜¯çŸ­è¾¹
                scale_ratio = 960 / original_width
                new_width = 960
                new_height = int(original_height * scale_ratio)
            else:
                # é«˜åº¦æ˜¯çŸ­è¾¹
                scale_ratio = 960 / original_height
                new_height = 960
                new_width = int(original_width * scale_ratio)
            
            # å¦‚æœæ–°å°ºå¯¸è¶…è¿‡åŸå°ºå¯¸ï¼Œåˆ™ä¸æ”¾å¤§ï¼Œä¿æŒåŸå°ºå¯¸
            if new_width > original_width or new_height > original_height:
                logger.debug(f"Image already smaller than target size, keeping original: {original_width}x{original_height}")
                return image
            
            # ä½¿ç”¨é«˜è´¨é‡é‡é‡‡æ ·è¿›è¡Œç¼©æ”¾
            resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            logger.debug(f"Resized image for LLaMA: {original_width}x{original_height} -> {new_width}x{new_height}")
            
            return resized_image
            
        except Exception as e:
            logger.warning(f"Failed to resize image for LLaMA, using original: {e}")
            return image
    
    def _get_llama_description(self, image: Image.Image) -> str:
        """
        ä½¿ç”¨LLaMAæ¨¡å‹è·å–è˜‘è‡ç”Ÿé•¿æƒ…å†µæè¿°
        
        Args:
            image: PILå›¾åƒå¯¹è±¡
            
        Returns:
            LLaMAç”Ÿæˆçš„è˜‘è‡ç”Ÿé•¿æƒ…å†µæè¿°
        """
        if not self.llama_client:
            logger.warning("LLaMA client not available, skipping description generation")
            return ""
        
        try:
            # ä¸ºLLaMAå¤„ç†ç¼©æ”¾å›¾åƒï¼ˆå‡å°‘è¿ç®—é‡ï¼‰
            resized_image = self._resize_image_for_llama(image)
            
            # å°†ç¼©æ”¾åçš„PILå›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç 
            buffer = io.BytesIO()
            resized_image.save(buffer, format='JPEG', quality=85)  # ä½¿ç”¨é€‚ä¸­çš„è´¨é‡ä»¥å¹³è¡¡æ–‡ä»¶å¤§å°å’Œè´¨é‡
            image_data = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            # è°ƒç”¨LLaMA API
            description = self._call_llama_api(image_data)
            logger.debug(f"LLaMA generated description: {description}")
            return description
            
        except Exception as e:
            logger.error(f"Failed to get LLaMA description: {e}")
            return ""  # è¿”å›ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯é”™è¯¯ä¿¡æ¯ï¼Œé¿å…æ±¡æŸ“æè¿°
    
    def get_multimodal_embedding(self, image: Image.Image, text_description: str) -> Optional[List[float]]:
        """
        è·å–å›¾åƒå’Œæ–‡æœ¬çš„å¤šæ¨¡æ€CLIPå‘é‡ç¼–ç 
        
        Args:
            image: PILå›¾åƒå¯¹è±¡
            text_description: ç¯å¢ƒæ•°æ®çš„è¯­ä¹‰æè¿°æ–‡æœ¬
            
        Returns:
            512ç»´è”åˆå‘é‡åˆ—è¡¨ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # ç¡®ä¿å›¾åƒä¸ºRGBæ ¼å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # åŒæ—¶é¢„å¤„ç†å›¾åƒå’Œæ–‡æœ¬
            inputs = self.clip_processor(
                text=text_description,
                images=image, 
                return_tensors="pt", 
                padding=True,
                truncation=True
            ).to(self.device)
            
            # è·å–å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾
            with torch.no_grad():
                image_features = self.clip_model.get_image_features(pixel_values=inputs['pixel_values'])
                text_features = self.clip_model.get_text_features(
                    input_ids=inputs['input_ids'],
                    attention_mask=inputs['attention_mask']
                )
            
            # å¤šæ¨¡æ€ç‰¹å¾èåˆ - ä½¿ç”¨åŠ æƒå¹³å‡
            # å›¾åƒç‰¹å¾æƒé‡0.7ï¼Œæ–‡æœ¬ç‰¹å¾æƒé‡0.3ï¼ˆå¯æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´ï¼‰
            image_weight = 0.7
            text_weight = 0.3
            
            # å½’ä¸€åŒ–å„è‡ªçš„ç‰¹å¾
            image_features_norm = image_features / image_features.norm(dim=-1, keepdim=True)
            text_features_norm = text_features / text_features.norm(dim=-1, keepdim=True)
            
            # åŠ æƒèåˆ
            multimodal_features = (image_weight * image_features_norm + 
                                 text_weight * text_features_norm)
            
            # æœ€ç»ˆå½’ä¸€åŒ–
            embedding = multimodal_features.cpu().numpy()[0]
            embedding = embedding / np.linalg.norm(embedding)
            
            logger.debug(f"Generated multimodal embedding for text: '{text_description[:50]}...'")
            return embedding.tolist()
            
        except Exception as e:
            logger.error(f"Failed to get multimodal embedding: {e}")
            return None
    
    def get_image_embedding(self, image: Image.Image) -> Optional[List[float]]:
        """
        è·å–çº¯å›¾åƒçš„CLIPå‘é‡ç¼–ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ç”¨æ–¹æ³•ï¼‰
        
    
    def calculate_image_quality_score(self, image: Image.Image) -> float:
        """
        è®¡ç®—å›¾åƒè´¨é‡è¯„åˆ†(0-100)
        è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬æ¸…æ™°åº¦, äº®åº¦, å¯¹æ¯”åº¦ç­‰
        
        Args:
            image: PILå›¾åƒå¯¹è±¡
            
        Returns:
            å›¾åƒè´¨é‡è¯„åˆ†(0-100)
        """
        try:
            # ç¡®ä¿å›¾åƒä¸ºRGBæ ¼å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            img_array = np.array(image, dtype=np.float32)
            
            # 1. è®¡ç®—æ¸…æ™°åº¦ï¼ˆä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = np.mean(img_array, axis=2)
            
            # ä½¿ç”¨ç®€å•çš„æ¢¯åº¦è®¡ç®—è¾¹ç¼˜å¼ºåº¦
            # æ°´å¹³æ¢¯åº¦
            grad_x = np.abs(gray[:, 1:] - gray[:, :-1])
            # å‚ç›´æ¢¯åº¦
            grad_y = np.abs(gray[1:, :] - gray[:-1, :])
            
            # è®¡ç®—æ¢¯åº¦æ–¹å·®ä½œä¸ºæ¸…æ™°åº¦æŒ‡æ ‡
            sharpness = np.var(grad_x) + np.var(grad_y)
            # å½’ä¸€åŒ–åˆ°0-100ï¼Œç»éªŒå€¼ï¼šæ–¹å·®>500ä¸ºæ¸…æ™°
            sharpness_score = min(100, (sharpness / 500) * 100)
            
            # 2. è®¡ç®—äº®åº¦é€‚ä¸­æ€§ï¼ˆç†æƒ³äº®åº¦åœ¨100-180ä¹‹é—´ï¼‰
            brightness = np.mean(img_array)
            if 100 <= brightness <= 180:
                brightness_score = 100
            elif brightness < 100:
                brightness_score = (brightness / 100) * 100
            else:  # brightness > 180
                brightness_score = max(0, 100 - ((brightness - 180) / 75) * 100)
            
            # 3. è®¡ç®—å¯¹æ¯”åº¦ï¼ˆæ ‡å‡†å·®ï¼‰
            contrast = np.std(img_array)
            # å½’ä¸€åŒ–åˆ°0-100ï¼Œç»éªŒå€¼ï¼šæ ‡å‡†å·®>40ä¸ºè‰¯å¥½å¯¹æ¯”åº¦
            contrast_score = min(100, (contrast / 40) * 100)
            
            # 4. ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
            # æ¸…æ™°åº¦æƒé‡50%ï¼Œäº®åº¦æƒé‡30%ï¼Œå¯¹æ¯”åº¦æƒé‡20%
            quality_score = (
                0.5 * sharpness_score +
                0.3 * brightness_score +
                0.2 * contrast_score
            )
            
            logger.debug(f"Image quality: sharpness={sharpness_score:.1f}, "
                        f"brightness={brightness_score:.1f}, contrast={contrast_score:.1f}, "
                        f"overall={quality_score:.1f}")
            
            return round(quality_score, 2)
            
        except Exception as e:
            logger.error(f"Failed to calculate image quality score: {e}")
            # è¿”å›é»˜è®¤ä¸­ç­‰è´¨é‡åˆ†æ•°
            return 50.0
    
    def get_image_embedding(self, image: Image.Image) -> Optional[List[float]]:
        """
        è·å–çº¯å›¾åƒçš„CLIPå‘é‡ç¼–ç (ä¿ç•™ä½œä¸ºå¤‡ç”¨æ–¹æ³•)
        
        Args:
            image: PILå›¾åƒå¯¹è±¡
            
        Returns:
            512ç»´å‘é‡åˆ—è¡¨, å¤±è´¥è¿”å›None
        """
        try:
            # ç¡®ä¿å›¾åƒä¸ºRGBæ ¼å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # é¢„å¤„ç†å›¾åƒ
            inputs = self.clip_processor(
                images=image, 
                return_tensors="pt", 
                padding=True
            ).to(self.device)
            
            # è·å–å›¾åƒç‰¹å¾
            with torch.no_grad():
                image_features = self.clip_model.get_image_features(**inputs)
            
            # å½’ä¸€åŒ–å‘é‡ï¼ˆå¯¹ä½™å¼¦ç›¸ä¼¼åº¦å¾ˆé‡è¦ï¼‰
            embedding = image_features.cpu().numpy()[0]
            embedding = embedding / np.linalg.norm(embedding)
            
            return embedding.tolist()
            
        except Exception as e:
            logger.error(f"Failed to get image embedding: {e}")
            return None
    
    def parse_time_from_path(self, image_info: MushroomImageInfo) -> Dict[str, datetime]:
        """
        ä»å›¾åƒè·¯å¾„ä¿¡æ¯ä¸­è§£ææ—¶é—´
        
        Args:
            image_info: è˜‘è‡å›¾åƒä¿¡æ¯å¯¹è±¡
            
        Returns:
            åŒ…å«å„ç§æ—¶é—´ä¿¡æ¯çš„å­—å…¸
        """
        time_info = {
            'collection_datetime': image_info.collection_datetime,
            'collection_date': datetime.strptime(image_info.collection_date, '%Y%m%d'),
            'detailed_time': datetime.strptime(image_info.detailed_time, '%Y%m%d%H%M%S'),
            'date_folder': datetime.strptime(image_info.date_folder, '%Y%m%d')
        }
        
        # æ·»åŠ æ—¶é—´èŒƒå›´ï¼ˆç”¨äºæŸ¥è¯¢ç¯å¢ƒå‚æ•°ï¼‰
        collection_time = time_info['collection_datetime']
        time_info['query_start'] = collection_time - timedelta(minutes=30)  # å‰30åˆ†é’Ÿ
        time_info['query_end'] = collection_time + timedelta(minutes=30)    # å30åˆ†é’Ÿ
        
        return time_info
    
    def get_environmental_data(self, mushroom_id: str, time_info: Dict[str, datetime]) -> Optional[Dict]:
        """
        æ ¹æ®è˜‘è‡åº“å·å’Œæ—¶é—´ä¿¡æ¯è·å–ç¯å¢ƒå‚æ•°
        
        Args:
            mushroom_id: è˜‘è‡åº“å·
            time_info: æ—¶é—´ä¿¡æ¯å­—å…¸
            
        Returns:
            ç»“æ„åŒ–çš„ç¯å¢ƒå‚æ•°å­—å…¸, å¤±è´¥è¿”å›None
        """
        if not self.env_processor:
            logger.warning("Environment data processor not initialized, skipping environment data retrieval")
            return None
        
        try:
            collection_time = time_info['collection_datetime']
            # æ„å»ºä¸´æ—¶å›¾åƒè·¯å¾„ç”¨äºè®°å½•
            temp_image_path = f"{mushroom_id}/{collection_time.strftime('%Y%m%d')}/temp_image.jpg"
            
            # æ˜ å°„åº“æˆ¿å·ï¼šMinIOä¸­çš„åº“æˆ¿å· -> ç¯å¢ƒé…ç½®ä¸­çš„åº“æˆ¿å·
            mapped_room_id = self._map_room_id(mushroom_id)
            
            logger.debug(f"Querying environment data for room {mushroom_id} (mapped to {mapped_room_id}) at time {collection_time}")
            
            # ä½¿ç”¨æ˜ å°„åçš„åº“æˆ¿å·æŸ¥è¯¢ç¯å¢ƒæ•°æ®
            env_data = self.env_processor.get_environment_data(
                room_id=mapped_room_id,
                collection_time=collection_time,
                image_path=temp_image_path,
                time_window_minutes=1  # æŸ¥è¯¢å‰å1åˆ†é’Ÿçš„æ•°æ®
            )
            
            if env_data:
                logger.info(f"Successfully retrieved environment data for room {mushroom_id} (mapped to {mapped_room_id})")
                logger.debug(f"Semantic description for room {mushroom_id}: {env_data.get('semantic_description', 'N/A')}")
                return env_data
            else:
                logger.warning(f"No environment data found for room {mushroom_id} (mapped to {mapped_room_id})")
                return None
                
        except Exception as e:
            logger.error(f"Failed to get environment data for room {mushroom_id}: {e}")
            return None
    
    def process_single_image(self, image_info: MushroomImageInfo, 
                           save_to_db: bool = True) -> Optional[Dict]:
        """
        Process single image, parse time, get environment parameters, multimodal encoding
        Only save to database when complete data (image + environment data) is available
        
        Args:
            image_info: Mushroom image information
            save_to_db: Whether to save to database
            
        Returns:
            Processing result dictionary
        """
        try:
            logger.info(f"Processing image: {image_info.file_name}")
            
            # 1. ä»MinIOè·å–å›¾åƒ
            image = self.minio_client.get_image(image_info.file_path)
            if image is None:
                logger.warning(f"Failed to get image from MinIO: {image_info.file_path}")
                return None
            
            # 2. è§£ææ—¶é—´ä¿¡æ¯
            time_info = self.parse_time_from_path(image_info)
            
            # 3. è·å–ç¯å¢ƒå‚æ•°å’Œè¯­ä¹‰æè¿°
            env_data = self.get_environmental_data(image_info.mushroom_id, time_info)
            
            # 4. æ£€æŸ¥æ˜¯å¦è·å–åˆ°å®Œæ•´ç¯å¢ƒæ•°æ®
            if env_data is None:
                logger.warning(f"No environment data available for image {image_info.file_name}, using image-only encoding")
                # å¦‚æœæ²¡æœ‰ç¯å¢ƒæ•°æ®ï¼Œä½¿ç”¨çº¯å›¾åƒç¼–ç 
                embedding = self.get_image_embedding(image)
                if embedding is None:
                    logger.error(f"Failed to encode image: {image_info.file_name}")
                    return None
                
                return {
                    'image_info': image_info,
                    'embedding': embedding,
                    'time_info': time_info,
                    'environmental_data': None,
                    'processed_at': datetime.now(),
                    'saved_to_db': False,
                    'skip_reason': 'no_environment_data'
                }
            
            # 5. è®¡ç®—å›¾åƒè´¨é‡è¯„åˆ†
            logger.info(f"Calculating image quality score for {image_info.file_name}...")
            image_quality_score = self.calculate_image_quality_score(image)
            logger.info(f"Image quality score: {image_quality_score:.2f}/100")
            
            # 6. ä½¿ç”¨LLaMAæ¨¡å‹è·å–è˜‘è‡ç”Ÿé•¿æƒ…å†µæè¿°
            logger.info(f"Attempting to get LLaMA description for {image_info.file_name}...")
            llama_description = self._get_llama_description(image)
            
            # 7. æ„å»ºå®Œæ•´çš„æ–‡æœ¬æè¿°ï¼šèº«ä»½å…ƒæ•°æ® + LLaMAç”Ÿé•¿æè¿°
            identity_metadata = env_data.get('semantic_description', f"Mushroom Room {image_info.mushroom_id}, unknown stage, Day 0.")
            
            # ä½¿ç”¨èº«ä»½å…ƒæ•°æ®å’ŒLLaMAæè¿°è¿›è¡Œå¤šæ¨¡æ€ç¼–ç 
            text_for_embedding = identity_metadata
            if llama_description and not llama_description.startswith("å›¾åƒåˆ†æå¤±è´¥"):
                text_for_embedding = f"{identity_metadata} {llama_description}"
                logger.info(f"Using combined description for {image_info.file_name}: identity + LLaMA")
            else:
                if llama_description:
                    logger.warning(f"LLaMA description failed for {image_info.file_name}, using only identity metadata")
                else:
                    logger.info(f"LLaMA description empty for {image_info.file_name}, using only identity metadata")
            
            # 8. ä½¿ç”¨å¤šæ¨¡æ€ç¼–ç ï¼ˆå›¾åƒ + æ–‡æœ¬æè¿°ï¼‰
            embedding = self.get_multimodal_embedding(image, text_for_embedding)
            
            if embedding is None:
                logger.error(f"Failed to get multimodal embedding for image: {image_info.file_name}")
                return None
            
            logger.info(f"Generated multimodal embedding for {image_info.file_name}")
            
            # 9. å°†å›¾åƒè´¨é‡è¯„åˆ†å’ŒLLaMAæè¿°ä¿å­˜åˆ°ç¯å¢ƒæ•°æ®ä¸­
            env_data['image_quality_score'] = image_quality_score
            env_data['llama_description'] = llama_description if llama_description else "N/A"
            
            # 10. æ„å»ºç»“æœ
            result = {
                'image_info': image_info,
                'embedding': embedding,
                'time_info': time_info,
                'environmental_data': env_data,
                'processed_at': datetime.now()
            }
            
            # 11. åªæœ‰åœ¨è·å–åˆ°å®Œæ•´æ•°æ®æ—¶æ‰ä¿å­˜åˆ°æ•°æ®åº“
            if save_to_db:
                success = self._save_to_database(result)
                result['saved_to_db'] = success
                if success:
                    logger.info(f"Successfully processed and saved image: {image_info.file_name}")
                else:
                    logger.error(f"Failed to save image to database: {image_info.file_name}")
            else:
                result['saved_to_db'] = False
            
            return result
            
        except Exception as e:
            logger.error(f"Failed to process image {image_info.file_name}: {e}")
            return None
    
    def _save_to_database(self, result: Dict) -> bool:
        """
        ä¿å­˜å¤„ç†ç»“æœåˆ°æ•°æ®åº“
        åªæœ‰åœ¨è·å–åˆ°å®Œæ•´ç¯å¢ƒæ•°æ®æ—¶æ‰ä¿å­˜
        
        Args:
            result: å¤„ç†ç»“æœå­—å…¸
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        session = self.Session()
        try:
            image_info = result['image_info']
            env_data = result['environmental_data']
            
            # ç¡®ä¿æœ‰ç¯å¢ƒæ•°æ®æ‰ä¿å­˜
            if not env_data:
                logger.warning(f"No environment data available for {image_info.file_name}, skipping database save")
                return False
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = session.query(MushroomImageEmbedding).filter_by(
                image_path=image_info.file_path
            ).first()
            
            if existing:
                # æ›´æ–°ç°æœ‰è®°å½•
                existing.embedding = result['embedding']
                existing.collection_datetime = result['time_info']['collection_datetime']
                
                # æ›´æ–°ç¯å¢ƒæ•°æ®å­—æ®µ
                existing.room_id = env_data.get('room_id', image_info.mushroom_id)
                existing.in_date = env_data.get('in_date', result['time_info']['collection_datetime'].date())
                existing.in_num = env_data.get('in_num', 0)
                existing.growth_day = env_data.get('growth_day', 0)
                existing.air_cooler_config = env_data.get('air_cooler_config', '{}')
                existing.fresh_fan_config = env_data.get('fresh_fan_config', '{}')
                existing.light_count = env_data.get('light_count', 0)
                existing.light_config = env_data.get('light_config', '{}')
                existing.humidifier_count = env_data.get('humidifier_count', 0)
                existing.humidifier_config = env_data.get('humidifier_config', '{}')
                existing.env_sensor_status = env_data.get('env_sensor_status', '{}')
                existing.semantic_description = env_data.get('semantic_description', 'æ— ç¯å¢ƒæ•°æ®ã€‚')
                existing.llama_description = env_data.get('llama_description', 'N/A')
                existing.image_quality_score = env_data.get('image_quality_score', None)
                existing.updated_at = datetime.now()
                
                logger.info(f"Updated database record for {image_info.file_name}")
            else:
                # åˆ›å»ºæ–°è®°å½•
                new_record = MushroomImageEmbedding(
                    image_path=image_info.file_path,
                    collection_datetime=result['time_info']['collection_datetime'],
                    embedding=result['embedding'],
                    room_id=env_data.get('room_id', image_info.mushroom_id),
                    in_date=env_data.get('in_date', result['time_info']['collection_datetime'].date()),
                    in_num=env_data.get('in_num', 0),
                    growth_day=env_data.get('growth_day', 0),
                    air_cooler_config=env_data.get('air_cooler_config', '{}'),
                    fresh_fan_config=env_data.get('fresh_fan_config', '{}'),
                    light_count=env_data.get('light_count', 0),
                    light_config=env_data.get('light_config', '{}'),
                    humidifier_count=env_data.get('humidifier_count', 0),
                    humidifier_config=env_data.get('humidifier_config', '{}'),
                    env_sensor_status=env_data.get('env_sensor_status', '{}'),
                    semantic_description=env_data.get('semantic_description', 'æ— ç¯å¢ƒæ•°æ®ã€‚'),
                    llama_description=env_data.get('llama_description', 'N/A'),
                    image_quality_score=env_data.get('image_quality_score', None)
                )
                
                session.add(new_record)
                logger.info(f"Created database record for {image_info.file_name}")
            
            session.commit()
            return True
            
        except Exception as e:
            logger.error(f"Failed to save to database: {e}")
            session.rollback()
            return False
        finally:
            session.close()
    
    def batch_process_images(self, mushroom_id: Optional[str] = None, 
                           date_filter: Optional[str] = None,
                           batch_size: int = 10) -> Dict[str, int]:
        """
        æ‰¹é‡å¤„ç†å›¾åƒ
        
        Args:
            mushroom_id: è˜‘è‡åº“å·è¿‡æ»¤
            date_filter: æ—¥æœŸè¿‡æ»¤ (YYYYMMDD)
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            å¤„ç†ç»Ÿè®¡ç»“æœ
        """
        logger.info("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†å›¾åƒ")
        
        # è·å–æ‰€æœ‰è˜‘è‡å›¾åƒ
        all_images = self.processor.get_mushroom_images(
            mushroom_id=mushroom_id,
            date_filter=date_filter
        )
        
        if not all_images:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å›¾åƒ")
            return {'total': 0, 'success': 0, 'failed': 0, 'skipped': 0}
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(all_images)} å¼ å›¾åƒå¾…å¤„ç†")
        
        stats = {'total': len(all_images), 'success': 0, 'failed': 0, 'skipped': 0}
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(all_images), batch_size):
            batch = all_images[i:i + batch_size]
            logger.info(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(all_images)-1)//batch_size + 1}")
            
            for image_info in batch:
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
                    if self._is_already_processed(image_info.file_path):
                        logger.info(f"â­ï¸ è·³è¿‡å·²å¤„ç†å›¾åƒ: {image_info.file_name}")
                        stats['skipped'] += 1
                        continue
                    
                    # å¤„ç†å›¾åƒ
                    result = self.process_single_image(image_info, save_to_db=True)
                    
                    if result and result.get('saved_to_db', False):
                        stats['success'] += 1
                    else:
                        stats['failed'] += 1
                        
                except Exception as e:
                    logger.error(f"âŒ æ‰¹å¤„ç†ä¸­å¤„ç†å›¾åƒå¤±è´¥ {image_info.file_name}: {e}")
                    stats['failed'] += 1
        
        logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ - æ€»è®¡: {stats['total']}, "
                   f"æˆåŠŸ: {stats['success']}, å¤±è´¥: {stats['failed']}, è·³è¿‡: {stats['skipped']}")
        
        return stats
    
    def _is_already_processed(self, image_path: str) -> bool:
        """æ£€æŸ¥å›¾åƒæ˜¯å¦å·²ç»å¤„ç†è¿‡"""
        session = self.Session()
        try:
            existing = session.query(MushroomImageEmbedding).filter_by(
                image_path=image_path
            ).first()
            return existing is not None
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
            return False
        finally:
            session.close()
    
    def get_processing_statistics(self) -> Dict:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        session = self.Session()
        try:
            from sqlalchemy import func
            
            # æ€»å¤„ç†æ•°é‡
            total_count = session.query(MushroomImageEmbedding).count()
            
            # æŒ‰åº“æˆ¿åˆ†ç»„ç»Ÿè®¡
            room_stats = session.query(
                MushroomImageEmbedding.room_id,
                func.count(MushroomImageEmbedding.id).label('count')
            ).group_by(MushroomImageEmbedding.room_id).all()
            
            # æŒ‰ç”Ÿé•¿å¤©æ•°èŒƒå›´åˆ†ç»„ç»Ÿè®¡
            growth_day_ranges = [
                ('1-7å¤©', 1, 7),
                ('8-14å¤©', 8, 14),
                ('15-21å¤©', 15, 21),
                ('22-27å¤©', 22, 27),
                ('28å¤©ä»¥ä¸Š', 28, 999)
            ]
            
            growth_day_stats = {}
            for label, min_day, max_day in growth_day_ranges:
                count = session.query(MushroomImageEmbedding).filter(
                    MushroomImageEmbedding.growth_day >= min_day,
                    MushroomImageEmbedding.growth_day <= max_day
                ).count()
                growth_day_stats[label] = count
            
            # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
            date_stats = session.query(
                MushroomImageEmbedding.in_date,
                func.count(MushroomImageEmbedding.id).label('count')
            ).group_by(MushroomImageEmbedding.in_date).all()
            
            # æœ‰ç¯å¢ƒæ§åˆ¶ç­–ç•¥çš„è®°å½•æ•°
            with_env_control = session.query(MushroomImageEmbedding).filter(
                MushroomImageEmbedding.semantic_description != 'æ— ç¯å¢ƒæ•°æ®ã€‚'
            ).count()
            
            # è¡¥å…‰ç¯ä½¿ç”¨ç»Ÿè®¡
            light_usage = session.query(
                MushroomImageEmbedding.light_count,
                func.count(MushroomImageEmbedding.id).label('count')
            ).group_by(MushroomImageEmbedding.light_count).all()
            
            # å›¾åƒè´¨é‡ç»Ÿè®¡
            avg_quality = session.query(
                func.avg(MushroomImageEmbedding.image_quality_score)
            ).scalar()
            
            quality_ranges = [
                ('ä¼˜ç§€(80-100)', 80, 100),
                ('è‰¯å¥½(60-80)', 60, 80),
                ('ä¸€èˆ¬(40-60)', 40, 60),
                ('è¾ƒå·®(0-40)', 0, 40)
            ]
            
            quality_stats = {}
            for label, min_score, max_score in quality_ranges:
                count = session.query(MushroomImageEmbedding).filter(
                    MushroomImageEmbedding.image_quality_score >= min_score,
                    MushroomImageEmbedding.image_quality_score < max_score
                ).count()
                quality_stats[label] = count
            
            return {
                'total_processed': total_count,
                'with_environmental_control': with_env_control,
                'room_distribution': {str(room_id): count for room_id, count in room_stats},
                'growth_day_distribution': growth_day_stats,
                'date_distribution': {str(date): count for date, count in date_stats},
                'light_usage_distribution': {f'light_{count}': usage for count, usage in light_usage},
                'image_quality_stats': {
                    'average_score': round(avg_quality, 2) if avg_quality else None,
                    'distribution': quality_stats
                },
                'processing_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
        finally:
            session.close()

    def validate_system_with_limited_samples(self, max_per_mushroom: int = 3) -> Dict[str, Any]:
        """
        Validate system functionality, process limited number of images per mushroom room
        Only save to database when complete data is available
        
        Args:
            max_per_mushroom: Maximum number of images to process per mushroom room
            
        Returns:
            Validation result statistics
        """
        logger.info(f"Starting system validation with max {max_per_mushroom} images per room")
        
        # è·å–æ‰€æœ‰å›¾åƒå¹¶æŒ‰åº“æˆ¿åˆ†ç»„
        all_images = self.processor.get_mushroom_images()
        mushroom_groups = {}
        
        for img in all_images:
            if img.mushroom_id not in mushroom_groups:
                mushroom_groups[img.mushroom_id] = []
            mushroom_groups[img.mushroom_id].append(img)
        
        logger.info(f"Found {len(mushroom_groups)} rooms: {sorted(mushroom_groups.keys())}")
        
        validation_results = {
            'mushroom_ids': sorted(mushroom_groups.keys()),
            'total_mushrooms': len(mushroom_groups),
            'processed_per_mushroom': {},
            'total_processed': 0,
            'total_success': 0,
            'total_failed': 0,
            'total_skipped': 0,
            'total_no_env_data': 0
        }
        
        # å¯¹æ¯ä¸ªåº“æˆ¿å¤„ç†æœ‰é™æ•°é‡çš„å›¾åƒ
        for mushroom_id in sorted(mushroom_groups.keys()):
            logger.info(f"Validating room {mushroom_id}...")
            
            images = mushroom_groups[mushroom_id]
            processed_count = 0
            success_count = 0
            failed_count = 0
            skipped_count = 0
            no_env_data_count = 0
            
            # æ‰¾åˆ°æœªå¤„ç†çš„å›¾åƒ
            for img in images:
                if processed_count >= max_per_mushroom:
                    break
                
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
                    if self._is_already_processed(img.file_path):
                        skipped_count += 1
                        logger.info(f"Skipping already processed image: {img.file_name}")
                        continue
                    
                    # å¤„ç†å›¾åƒ
                    logger.info(f"Processing image: {img.file_name}")
                    result = self.process_single_image(img, save_to_db=True)
                    
                    if result:
                        if result.get('saved_to_db', False):
                            success_count += 1
                            logger.info(f"Successfully processed and saved: {img.file_name}")
                        elif result.get('skip_reason') == 'no_environment_data':
                            no_env_data_count += 1
                            logger.warning(f"Processed but no environment data: {img.file_name}")
                        else:
                            failed_count += 1
                            logger.error(f"Processing failed: {img.file_name}")
                    else:
                        failed_count += 1
                        logger.error(f"Processing returned None: {img.file_name}")
                    
                    processed_count += 1
                    
                except Exception as e:
                    failed_count += 1
                    logger.error(f"Exception processing {img.file_name}: {e}")
                    processed_count += 1
            
            # è®°å½•è¯¥åº“æˆ¿çš„ç»“æœ
            validation_results['processed_per_mushroom'][mushroom_id] = {
                'processed': processed_count,
                'success': success_count,
                'failed': failed_count,
                'skipped': skipped_count,
                'no_env_data': no_env_data_count,
                'total_images': len(images)
            }
            
            validation_results['total_processed'] += processed_count
            validation_results['total_success'] += success_count
            validation_results['total_failed'] += failed_count
            validation_results['total_skipped'] += skipped_count
            validation_results['total_no_env_data'] += no_env_data_count
            
            logger.info(f"Room {mushroom_id} results: processed={processed_count}, success={success_count}, "
                       f"failed={failed_count}, skipped={skipped_count}, no_env_data={no_env_data_count}")
        
        logger.info(f"System validation completed - total_processed: {validation_results['total_processed']}, "
                   f"success: {validation_results['total_success']}, failed: {validation_results['total_failed']}, "
                   f"skipped: {validation_results['total_skipped']}, no_env_data: {validation_results['total_no_env_data']}")
        
        return validation_results


def create_mushroom_encoder() -> MushroomImageEncoder:
    """åˆ›å»ºè˜‘è‡å›¾åƒç¼–ç å™¨å®ä¾‹"""
    return MushroomImageEncoder()


if __name__ == "__main__":


    try:
        # Initialize encoder
        encoder = create_mushroom_encoder()
        print('âœ… Encoder initialized successfully')

        # Test system validation with limited samples
        print('ğŸ” Running system validation with limited samples...')
        validation_results = encoder.validate_system_with_limited_samples(max_per_mushroom=2)

        print('ğŸ“Š Validation Results:')
        print(f'   Total mushrooms: {validation_results["total_mushrooms"]}')
        print(f'   Mushroom IDs: {validation_results["mushroom_ids"]}')
        print(f'   Total processed: {validation_results["total_processed"]}')
        print(f'   Total success: {validation_results["total_success"]}')
        print(f'   Total failed: {validation_results["total_failed"]}')
        print(f'   Total skipped: {validation_results["total_skipped"]}')
        print(f'   No env data: {validation_results["total_no_env_data"]}')

        print('\nğŸ“ˆ Per-mushroom breakdown:')
        for mushroom_id, stats in validation_results['processed_per_mushroom'].items():
            print(f'   Room {mushroom_id}: processed={stats["processed"]}, success={stats["success"]}, failed={stats["failed"]}, no_env_data={stats["no_env_data"]}')

        # Get processing statistics
        print('\nğŸ“‹ Getting processing statistics...')
        processing_stats = encoder.get_processing_statistics()
        print(f'   Total records in database: {processing_stats.get("total_processed", 0)}')
        print(f'   Records with environmental control: {processing_stats.get("with_environmental_control", 0)}')

        print('\nâœ… Multimodal CLIP encoding system test completed successfully!')

    except Exception as e:
        print(f'âŒ Test failed: {e}')
        import traceback
        import sys
        traceback.print_exc()
        sys.exit(1)
