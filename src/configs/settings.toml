[default]
[default.data_source_url]
# data
mushroom_ledger="http://{host}/service/monitor/register/ledger/page/list" #蘑菇台账接口
realtime_data="http://{host}:{port}/algorithm/integration/realtime" # 实时数据接口
history_data="http://{host}:{port}/algorithm/integration/history" #历史数据接口
history_data1 = "http://{host}/service/monitor/device/insight/history/monitor"#历史数据查询——苏浩浩提供接口
history_cal_bak="http://{host}:9277/calculate/history/query/sensitive"#基于tdengine封装的历史数据查询接口
history_cal="http://{host}/scada-service/calculate/history/query/sensitive"#基于tdengine封装的历史数据查询接口
real_time_batch_bak="http://{host}:9277/edge/real/query/batch"
real_time_batch="http://{host}/scada-service/edge/real/query/batch"
write_cmd="http://{}:9277/edge/device/point/cmd/private" # 发送指令
llama_completions="http://{host}:{port}/chat/completions"
prompt_mushroom_description="prompts:/growth_stage_describe/4"
prompt_mushroom_description_bak="http://{host}/prompt/api/v1/prompts/role-instruction/active"
prompt_login="http://{host}/prompt/api/v1/auth/login"

[development]
[development.host]
host="10.77.77.39"
port=7063
[development.pgsql]
database_type = "postgresql"
driver = "psycopg"
host = "10.77.77.39"
port = 5432
database_name = "mushroom_algorithm"

[development.mysql]
database_type = "mysql"
driver = "pymysql"
host = "10.77.77.39"
port = 3306
database_name = "lenovo_algorithm_db"
[development.redis]
host="10.77.77.39"
port=26379

[development.minio]
endpoint = "10.77.77.39:9000"
secure = false
bucket = "mogu"
region = "us-east-1"
mlflow_s3_endpoint_url = "10.77.77.39:9000"
mlflow_default_artifact_root = "s3://mogu"
minio_bucket_name = "mogu"

[development.mlflow]
host = "10.77.77.39"
port="5000"


[development.llama]
llama_host = "10.77.77.49"
llama_port = "7001"
model = "qwen3-vl-4b"
llama_completions = "http://{0}:{1}/v1/chat/completions"
enabled = true  # 是否启用LLaMA描述生成
timeout = 600   # API调用超时时间（秒）
mushroom_descripe_prompt = "" # Loaded from MLflow Prompt Registry: growth_stage_describe


[development.llama_vl]
llama_host = "10.77.77.49"
llama_port = "7001"
model = "qwen3-vl-2b-instruct"
llama_completions = "http://{0}:{1}/v1/chat/completions"
enabled = true  # 是否启用LLaMA描述生成
timeout = 600   # API调用超时时间（秒）
temperature = 0.3
max_tokens = 2048
top_p = 0.2
image_width = 960
image_height = 960
device = "cuda" # 即使是API调用，保留此配置以兼容可能的本地加载逻辑
mushroom_descripe_prompt = "" # Loaded from MLflow Prompt Registry: growth_stage_describe




[production]
[production.host]
host="172.17.0.1"
port=7063
[production.pgsql]
database_type = "postgresql"
driver = "psycopg"
host = "postgres_db"
port = 5432
database_name = "mushroom_algorithm"

[production.mysql]
database_type = "mysql"
driver = "pymysql"
host = "mysql_db"
port = 3306
database_name = "lenovo_algorithm_db"
[production.redis]
host="172.17.0.1"
port = 26379

[production.minio]
endpoint = "172.17.0.1:9000"
secure = false
bucket = "mogu"
region = "us-east-1"
mlflow_s3_endpoint_url = "172.17.0.1:9000"
mlflow_default_artifact_root = "s3://mogu"
minio_bucket_name = "mogu"

[production.mlflow]
host = "mlflow"
port="5000"

[production.llama]
llama_host = "172.17.0.1"
llama_port = "7002"
model = "llama-mushroom-light.service"
llama_completions = "http://{0}:{1}/v1/chat/completions"
enabled = true  # 是否启用LLaMA描述生成
timeout = 600   # API调用超时时间（秒）

[production.llama_vl]
llama_host = "172.17.0.1"
llama_port = "7002"
model = "llama-mushroom-vl-light.service"
llama_completions = "http://{0}:{1}/vl-light/v1/chat/completions"
enabled = true  # 是否启用LLaMA描述生成
timeout = 600   # API调用超时时间（秒）
