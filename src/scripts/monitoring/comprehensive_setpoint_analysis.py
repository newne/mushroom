#!/usr/bin/env python3
"""
å…¨é¢è®¾å®šç‚¹å˜æ›´ç›‘æ§åˆ†æè„šæœ¬

æŒ‰ç…§ç”¨æˆ·è¦æ±‚æ‰§è¡Œæ¯å°æ—¶è®¾å®šç‚¹å˜æ›´ç›‘æ§ä»»åŠ¡çš„å…·ä½“æ“ä½œæ­¥éª¤ï¼š
1. æŸ¥çœ‹è¿‡å»24å°æ—¶å†…çš„è®¾å®šç‚¹å˜æ›´æƒ…å†µ
2. ä½¿ç”¨batch_monitor_setpoint_changeså‡½æ•°æ‰§è¡Œæ‰¹é‡åˆ†æ
3. åˆ†æå®ŒæˆåæŸ¥è¯¢æ•°æ®åº“éªŒè¯æ•°æ®å®Œæ•´æ€§
4. æ£€æŸ¥ç³»ç»Ÿè¿è¡ŒçŠ¶æ€
5. é€æ­¥æ‰©å±•åˆ†ææ—¶é—´èŒƒå›´è‡³2025-12-19
6. éªŒè¯æ¯æ¬¡åˆ†æç»“æœçš„æ­£ç¡®æ€§
7. è®°å½•å…³é”®æŒ‡æ ‡
8. å¼‚å¸¸å¤„ç†å’ŒæŠ¥å‘Š
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
import time

# ä½¿ç”¨BASE_DIRç»Ÿä¸€ç®¡ç†è·¯å¾„
from global_const.global_const import ensure_src_path

ensure_src_path()

try:
    from utils.setpoint_change_monitor import (
        batch_monitor_setpoint_changes,
        validate_batch_monitoring_environment,
        create_setpoint_monitor_table,
    )
    from global_const.global_const import pgsql_engine
    from sqlalchemy import text
    from loguru import logger
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–åŒ…å¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ")
    sys.exit(1)


class SetpointAnalysisManager:
    """è®¾å®šç‚¹åˆ†æç®¡ç†å™¨"""

    def __init__(self):
        self.analysis_results = []
        self.total_changes_detected = 0
        self.total_records_stored = 0
        self.analysis_start_time = datetime.now()

    def step1_check_past_24h_changes(self):
        """æ­¥éª¤1: æŸ¥çœ‹è¿‡å»24å°æ—¶å†…çš„è®¾å®šç‚¹å˜æ›´æƒ…å†µ"""
        print("ğŸ” æ­¥éª¤1: æŸ¥çœ‹è¿‡å»24å°æ—¶å†…çš„è®¾å®šç‚¹å˜æ›´æƒ…å†µ")
        print("=" * 60)

        try:
            with pgsql_engine.connect() as conn:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                result = conn.execute(
                    text("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'device_setpoint_changes'
                    )
                """)
                )
                table_exists = result.scalar()

                if table_exists:
                    # æŸ¥è¯¢è¿‡å»24å°æ—¶çš„è®°å½•
                    result = conn.execute(
                        text("""
                        SELECT 
                            COUNT(*) as total_records,
                            COUNT(DISTINCT room_id) as rooms_count,
                            COUNT(DISTINCT device_type) as device_types_count,
                            MIN(change_time) as earliest_change,
                            MAX(change_time) as latest_change
                        FROM device_setpoint_changes 
                        WHERE change_time >= NOW() - INTERVAL '24 hours'
                    """)
                    )

                    row = result.fetchone()
                    if row and row[0] > 0:
                        print(f"ğŸ“Š è¿‡å»24å°æ—¶è®¾å®šç‚¹å˜æ›´ç»Ÿè®¡:")
                        print(f"   æ€»è®°å½•æ•°: {row[0]}")
                        print(f"   æ¶‰åŠåº“æˆ¿: {row[1]}")
                        print(f"   è®¾å¤‡ç±»å‹: {row[2]}")
                        print(f"   æœ€æ—©å˜æ›´: {row[3]}")
                        print(f"   æœ€æ–°å˜æ›´: {row[4]}")

                        # æŒ‰åº“æˆ¿ç»Ÿè®¡
                        result = conn.execute(
                            text("""
                            SELECT room_id, COUNT(*) as change_count
                            FROM device_setpoint_changes 
                            WHERE change_time >= NOW() - INTERVAL '24 hours'
                            GROUP BY room_id
                            ORDER BY change_count DESC
                        """)
                        )

                        print(f"\\nğŸ“ å„åº“æˆ¿å˜æ›´ç»Ÿè®¡:")
                        for room_row in result:
                            print(f"   åº“æˆ¿ {room_row[0]}: {room_row[1]} ä¸ªå˜æ›´")

                    else:
                        print("ğŸ“Š è¿‡å»24å°æ—¶æ— è®¾å®šç‚¹å˜æ›´è®°å½•")

                    # æŒ‰è®¾å¤‡ç±»å‹ç»Ÿè®¡
                    result = conn.execute(
                        text("""
                        SELECT device_type, COUNT(*) as change_count
                        FROM device_setpoint_changes 
                        WHERE change_time >= NOW() - INTERVAL '24 hours'
                        GROUP BY device_type
                        ORDER BY change_count DESC
                    """)
                    )

                    device_stats = result.fetchall()
                    if device_stats:
                        print(f"\\nğŸ”§ è®¾å¤‡ç±»å‹å˜æ›´ç»Ÿè®¡:")
                        for device_row in device_stats:
                            print(f"   {device_row[0]}: {device_row[1]} ä¸ªå˜æ›´")
                else:
                    print("âš ï¸ è®¾å®šç‚¹å˜æ›´è¡¨ä¸å­˜åœ¨ï¼Œå°†åœ¨æ‰§è¡Œç›‘æ§æ—¶åˆ›å»º")

        except Exception as e:
            print(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
            return False

        return True

    def step2_execute_batch_analysis(self, start_time, end_time, description=""):
        """æ­¥éª¤2: ä½¿ç”¨batch_monitor_setpoint_changeså‡½æ•°æ‰§è¡Œæ‰¹é‡åˆ†æ"""
        print(f"\\nğŸš€ æ­¥éª¤2: æ‰§è¡Œæ‰¹é‡åˆ†æ {description}")
        print("=" * 60)

        time_range = end_time - start_time
        print(
            f"åˆ†ææ—¶é—´èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_time.strftime('%Y-%m-%d %H:%M:%S')}"
        )
        print(f"æ—¶é—´è·¨åº¦: {time_range.days}å¤© {time_range.seconds // 3600}å°æ—¶")

        try:
            # æ‰§è¡Œæ‰¹é‡ç›‘æ§
            print("\\nğŸ” æ­£åœ¨æ‰§è¡Œæ‰¹é‡è®¾å®šç‚¹å˜æ›´åˆ†æ...")
            analysis_start = datetime.now()

            result = batch_monitor_setpoint_changes(
                start_time=start_time, end_time=end_time, store_results=True
            )

            analysis_duration = (datetime.now() - analysis_start).total_seconds()

            if result["success"]:
                print("âœ… æ‰¹é‡åˆ†ææ‰§è¡ŒæˆåŠŸ")

                # è®°å½•åˆ†æç»“æœ
                analysis_record = {
                    "start_time": start_time,
                    "end_time": end_time,
                    "description": description,
                    "total_rooms": result["total_rooms"],
                    "successful_rooms": result["successful_rooms"],
                    "total_changes": result["total_changes"],
                    "stored_records": result["stored_records"],
                    "processing_time": result["processing_time"],
                    "analysis_duration": analysis_duration,
                    "changes_by_room": result["changes_by_room"],
                    "error_rooms": result["error_rooms"],
                }

                self.analysis_results.append(analysis_record)
                self.total_changes_detected += result["total_changes"]
                self.total_records_stored += result["stored_records"]

                # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
                print(f"\\nğŸ“Š åˆ†æç»“æœç»Ÿè®¡:")
                print(
                    f"   å¤„ç†åº“æˆ¿æ•°: {result['successful_rooms']}/{result['total_rooms']}"
                )
                print(f"   æ£€æµ‹å˜æ›´æ•°: {result['total_changes']} ä¸ª")
                print(f"   å­˜å‚¨è®°å½•æ•°: {result['stored_records']} æ¡")
                print(f"   å¤„ç†è€—æ—¶: {result['processing_time']:.2f} ç§’")
                print(f"   åˆ†æè€—æ—¶: {analysis_duration:.2f} ç§’")

                if result["error_rooms"]:
                    print(f"   å¤±è´¥åº“æˆ¿: {result['error_rooms']}")

                # æ˜¾ç¤ºå„åº“æˆ¿ç»Ÿè®¡
                print(f"\\nğŸ  å„åº“æˆ¿å˜æ›´è¯¦æƒ…:")
                for room_id, change_count in result["changes_by_room"].items():
                    status = "ğŸ”´" if change_count > 0 else "ğŸŸ¢"
                    print(f"   {status} åº“æˆ¿ {room_id}: {change_count} ä¸ªå˜æ›´")

                return result
            else:
                print("âŒ æ‰¹é‡åˆ†ææ‰§è¡Œå¤±è´¥")
                return None

        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ†æå¼‚å¸¸: {e}")
            return None

    def step3_verify_data_integrity(self, expected_changes=None):
        """æ­¥éª¤3: åˆ†æå®ŒæˆåæŸ¥è¯¢æ•°æ®åº“éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œå‡†ç¡®æ€§"""
        print(f"\\nğŸ” æ­¥éª¤3: éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œå‡†ç¡®æ€§")
        print("=" * 60)

        try:
            with pgsql_engine.connect() as conn:
                # æŸ¥è¯¢æœ€è¿‘å­˜å‚¨çš„è®°å½•
                result = conn.execute(
                    text("""
                    SELECT 
                        COUNT(*) as total_records,
                        COUNT(DISTINCT room_id) as rooms_count,
                        COUNT(DISTINCT device_type) as device_types_count,
                        COUNT(DISTINCT change_type) as change_types_count,
                        MIN(change_time) as earliest_change,
                        MAX(change_time) as latest_change,
                        MIN(detection_time) as earliest_detection,
                        MAX(detection_time) as latest_detection
                    FROM device_setpoint_changes 
                    WHERE detection_time >= :start_time
                """),
                    {"start_time": self.analysis_start_time},
                )

                row = result.fetchone()
                if row:
                    print(f"ğŸ“Š æ•°æ®å®Œæ•´æ€§éªŒè¯:")
                    print(f"   å­˜å‚¨è®°å½•æ•°: {row[0]}")
                    print(f"   æ¶‰åŠåº“æˆ¿æ•°: {row[1]}")
                    print(f"   è®¾å¤‡ç±»å‹æ•°: {row[2]}")
                    print(f"   å˜æ›´ç±»å‹æ•°: {row[3]}")
                    print(f"   å˜æ›´æ—¶é—´èŒƒå›´: {row[4]} ~ {row[5]}")
                    print(f"   æ£€æµ‹æ—¶é—´èŒƒå›´: {row[6]} ~ {row[7]}")

                    # éªŒè¯æ•°æ®ä¸€è‡´æ€§
                    if expected_changes is not None:
                        if row[0] == expected_changes:
                            print(
                                f"âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡: å­˜å‚¨è®°å½•æ•°({row[0]})ä¸é¢„æœŸ({expected_changes})ä¸€è‡´"
                            )
                        else:
                            print(
                                f"âš ï¸ æ•°æ®ä¸€è‡´æ€§å¼‚å¸¸: å­˜å‚¨è®°å½•æ•°({row[0]})ä¸é¢„æœŸ({expected_changes})ä¸ä¸€è‡´"
                            )

                    # æ£€æŸ¥æ•°æ®è´¨é‡
                    result = conn.execute(
                        text("""
                        SELECT 
                            COUNT(CASE WHEN previous_value IS NULL THEN 1 END) as null_previous,
                            COUNT(CASE WHEN current_value IS NULL THEN 1 END) as null_current,
                            COUNT(CASE WHEN ABS(current_value - previous_value) = 0 THEN 1 END) as zero_magnitude
                        FROM device_setpoint_changes 
                        WHERE detection_time >= :start_time
                    """),
                        {"start_time": self.analysis_start_time},
                    )

                    quality_row = result.fetchone()
                    if quality_row:
                        print(f"\\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
                        print(f"   ç©ºçš„å‰å€¼è®°å½•: {quality_row[0]}")
                        print(f"   ç©ºçš„å½“å‰å€¼è®°å½•: {quality_row[1]}")
                        print(f"   é›¶å˜åŒ–å¹…åº¦è®°å½•: {quality_row[2]}")

                        if all(count == 0 for count in quality_row):
                            print("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
                        else:
                            print("âš ï¸ å‘ç°æ•°æ®è´¨é‡é—®é¢˜")

                # æŒ‰å˜æ›´ç±»å‹ç»Ÿè®¡
                result = conn.execute(
                    text("""
                    SELECT change_type, COUNT(*) as count
                    FROM device_setpoint_changes 
                    WHERE detection_time >= :start_time
                    GROUP BY change_type
                    ORDER BY count DESC
                """),
                    {"start_time": self.analysis_start_time},
                )

                change_type_stats = result.fetchall()
                if change_type_stats:
                    print(f"\\nğŸ“ˆ å˜æ›´ç±»å‹åˆ†å¸ƒ:")
                    for type_row in change_type_stats:
                        print(f"   {type_row[0]}: {type_row[1]} ä¸ªå˜æ›´")

                return True

        except Exception as e:
            print(f"âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            return False

    def step4_check_system_status(self):
        """æ­¥éª¤4: æ£€æŸ¥ç³»ç»Ÿè¿è¡ŒçŠ¶æ€ï¼Œç¡®è®¤ç›‘æ§ä»»åŠ¡æ‰§è¡Œæ­£å¸¸"""
        print(f"\\nğŸ”§ æ­¥éª¤4: æ£€æŸ¥ç³»ç»Ÿè¿è¡ŒçŠ¶æ€")
        print("=" * 60)

        try:
            # æ£€æŸ¥ç¯å¢ƒ
            print("ğŸ” éªŒè¯ç›‘æ§ç¯å¢ƒ...")
            if validate_batch_monitoring_environment():
                print("âœ… ç›‘æ§ç¯å¢ƒæ­£å¸¸")
            else:
                print("âŒ ç›‘æ§ç¯å¢ƒå¼‚å¸¸")
                return False

            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            print("\\nğŸ” æ£€æŸ¥æ•°æ®åº“è¿æ¥...")
            with pgsql_engine.connect() as conn:
                result = conn.execute(text("SELECT NOW()"))
                db_time = result.scalar()
                print(f"âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼Œå½“å‰æ—¶é—´: {db_time}")

            # æ£€æŸ¥è¡¨ç»“æ„
            print("\\nğŸ” æ£€æŸ¥è¡¨ç»“æ„...")
            with pgsql_engine.connect() as conn:
                result = conn.execute(
                    text("""
                    SELECT column_name, data_type, is_nullable
                    FROM information_schema.columns 
                    WHERE table_name = 'device_setpoint_changes'
                    ORDER BY ordinal_position
                """)
                )

                columns = result.fetchall()
                if columns:
                    print("âœ… è¡¨ç»“æ„æ­£å¸¸:")
                    for col in columns:
                        nullable = "NULL" if col[2] == "YES" else "NOT NULL"
                        print(f"   {col[0]}: {col[1]} {nullable}")
                else:
                    print("âŒ è¡¨ç»“æ„å¼‚å¸¸")
                    return False

            # æ£€æŸ¥åˆ†æç»“æœ
            print(f"\\nğŸ” æ£€æŸ¥åˆ†æç»“æœ...")
            if self.analysis_results:
                print(f"âœ… å·²å®Œæˆ {len(self.analysis_results)} æ¬¡åˆ†æ")
                print(f"   ç´¯è®¡æ£€æµ‹å˜æ›´: {self.total_changes_detected} ä¸ª")
                print(f"   ç´¯è®¡å­˜å‚¨è®°å½•: {self.total_records_stored} æ¡")

                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                error_count = sum(
                    len(result["error_rooms"]) for result in self.analysis_results
                )
                if error_count == 0:
                    print("âœ… æ— é”™è¯¯è®°å½•")
                else:
                    print(f"âš ï¸ å‘ç° {error_count} ä¸ªåº“æˆ¿å¤„ç†é”™è¯¯")
            else:
                print("âš ï¸ å°šæœªæ‰§è¡Œåˆ†æ")

            return True

        except Exception as e:
            print(f"âŒ ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
            return False

    def step5_expand_analysis_timerange(self, target_date):
        """æ­¥éª¤5: é€æ­¥æ‰©å±•åˆ†ææ—¶é—´èŒƒå›´"""
        print(f"\\nğŸ“… æ­¥éª¤5: æ‰©å±•åˆ†ææ—¶é—´èŒƒå›´è‡³ {target_date}")
        print("=" * 60)

        current_time = datetime.now()
        target_datetime = datetime.combine(target_date, datetime.min.time())

        if target_datetime >= current_time:
            print("âŒ ç›®æ ‡æ—¥æœŸä¸èƒ½æ˜¯æœªæ¥æ—¶é—´")
            return False

        # è®¡ç®—éœ€è¦åˆ†æçš„æ—¶é—´æ®µ
        total_days = (current_time.date() - target_date).days
        print(f"éœ€è¦åˆ†æ {total_days} å¤©çš„å†å²æ•°æ®")

        # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ¬¡å¤„ç†7å¤©
        batch_days = 7
        batches = []

        current_end = current_time
        while current_end.date() > target_date:
            batch_start = max(current_end - timedelta(days=batch_days), target_datetime)
            batches.append((batch_start, current_end))
            current_end = batch_start

        print(f"\\nğŸ“‹ åˆ†æè®¡åˆ’: å…± {len(batches)} ä¸ªæ‰¹æ¬¡")
        for i, (start, end) in enumerate(batches, 1):
            days = (end - start).days
            print(
                f"   æ‰¹æ¬¡ {i}: {start.strftime('%Y-%m-%d')} ~ {end.strftime('%Y-%m-%d')} ({days}å¤©)"
            )

        # æ‰§è¡Œåˆ†æ‰¹åˆ†æ
        successful_batches = 0
        for i, (batch_start, batch_end) in enumerate(batches, 1):
            print(f"\\nğŸ” æ‰§è¡Œæ‰¹æ¬¡ {i}/{len(batches)}")

            # æ‰§è¡Œåˆ†æ
            result = self.step2_execute_batch_analysis(
                batch_start, batch_end, f"(æ‰¹æ¬¡ {i}/{len(batches)})"
            )

            if result:
                # éªŒè¯ç»“æœ
                if self.step3_verify_data_integrity(result["total_changes"]):
                    successful_batches += 1
                    print(f"âœ… æ‰¹æ¬¡ {i} å®Œæˆ")
                else:
                    print(f"âš ï¸ æ‰¹æ¬¡ {i} æ•°æ®éªŒè¯å¤±è´¥")
            else:
                print(f"âŒ æ‰¹æ¬¡ {i} æ‰§è¡Œå¤±è´¥")

            # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
            if not self.step4_check_system_status():
                print(f"âŒ ç³»ç»ŸçŠ¶æ€å¼‚å¸¸ï¼Œåœæ­¢åˆ†æ")
                break

            # æ‰¹æ¬¡é—´ä¼‘æ¯
            if i < len(batches):
                print("â³ æ‰¹æ¬¡é—´ä¼‘æ¯ 2 ç§’...")
                time.sleep(2)

        print(f"\\nğŸ“Š æ‰©å±•åˆ†æå®Œæˆ: {successful_batches}/{len(batches)} ä¸ªæ‰¹æ¬¡æˆåŠŸ")
        return successful_batches == len(batches)

    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š"""
        print(f"\\nğŸ“‹ æœ€ç»ˆåˆ†ææŠ¥å‘Š")
        print("=" * 60)

        if not self.analysis_results:
            print("âŒ æ— åˆ†æç»“æœ")
            return

        total_analysis_time = (
            datetime.now() - self.analysis_start_time
        ).total_seconds()

        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   åˆ†ææ‰¹æ¬¡æ•°: {len(self.analysis_results)}")
        print(f"   ç´¯è®¡æ£€æµ‹å˜æ›´: {self.total_changes_detected} ä¸ª")
        print(f"   ç´¯è®¡å­˜å‚¨è®°å½•: {self.total_records_stored} æ¡")
        print(f"   æ€»åˆ†ææ—¶é—´: {total_analysis_time:.2f} ç§’")

        # æ—¶é—´èŒƒå›´ç»Ÿè®¡
        if self.analysis_results:
            earliest_start = min(
                result["start_time"] for result in self.analysis_results
            )
            latest_end = max(result["end_time"] for result in self.analysis_results)
            print(f"   åˆ†ææ—¶é—´èŒƒå›´: {earliest_start} ~ {latest_end}")

        # åº“æˆ¿ç»Ÿè®¡
        all_rooms = set()
        room_changes = {}

        for result in self.analysis_results:
            for room_id, changes in result["changes_by_room"].items():
                all_rooms.add(room_id)
                room_changes[room_id] = room_changes.get(room_id, 0) + changes

        print(f"\\nğŸ  åº“æˆ¿ç»Ÿè®¡:")
        print(f"   æ¶‰åŠåº“æˆ¿æ•°: {len(all_rooms)}")
        for room_id in sorted(all_rooms):
            total_changes = room_changes.get(room_id, 0)
            print(f"   åº“æˆ¿ {room_id}: {total_changes} ä¸ªå˜æ›´")

        # æ€§èƒ½ç»Ÿè®¡
        total_processing_time = sum(
            result["processing_time"] for result in self.analysis_results
        )
        if total_processing_time > 0:
            processing_rate = self.total_changes_detected / total_processing_time
            print(f"\\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
            print(f"   æ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f} ç§’")
            print(f"   å¤„ç†é€Ÿåº¦: {processing_rate:.1f} å˜æ›´/ç§’")

        # æ•°æ®è´¨é‡ç»Ÿè®¡
        storage_rate = (
            (self.total_records_stored / self.total_changes_detected * 100)
            if self.total_changes_detected > 0
            else 0
        )
        print(f"\\nğŸ“ˆ æ•°æ®è´¨é‡:")
        print(f"   å­˜å‚¨æˆåŠŸç‡: {storage_rate:.1f}%")

        if storage_rate == 100:
            print("âœ… æ‰€æœ‰æ£€æµ‹åˆ°çš„å˜æ›´éƒ½å·²æˆåŠŸå­˜å‚¨")
        else:
            print("âš ï¸ éƒ¨åˆ†å˜æ›´è®°å½•å­˜å‚¨å¤±è´¥")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å…¨é¢è®¾å®šç‚¹å˜æ›´ç›‘æ§åˆ†æç³»ç»Ÿ")
    print("=" * 80)

    # åˆ›å»ºåˆ†æç®¡ç†å™¨
    manager = SetpointAnalysisManager()

    try:
        # æ­¥éª¤1: æŸ¥çœ‹è¿‡å»24å°æ—¶å†…çš„è®¾å®šç‚¹å˜æ›´æƒ…å†µ
        if not manager.step1_check_past_24h_changes():
            print("âŒ æ­¥éª¤1å¤±è´¥ï¼Œç»ˆæ­¢åˆ†æ")
            return

        # æ­¥éª¤2: æ‰§è¡Œè¿‡å»24å°æ—¶çš„æ‰¹é‡åˆ†æ
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)

        result = manager.step2_execute_batch_analysis(
            start_time, end_time, "(è¿‡å»24å°æ—¶)"
        )

        if not result:
            print("âŒ æ­¥éª¤2å¤±è´¥ï¼Œç»ˆæ­¢åˆ†æ")
            return

        # æ­¥éª¤3: éªŒè¯æ•°æ®å®Œæ•´æ€§
        if not manager.step3_verify_data_integrity(result["total_changes"]):
            print("âŒ æ­¥éª¤3å¤±è´¥ï¼Œç»ˆæ­¢åˆ†æ")
            return

        # æ­¥éª¤4: æ£€æŸ¥ç³»ç»Ÿè¿è¡ŒçŠ¶æ€
        if not manager.step4_check_system_status():
            print("âŒ æ­¥éª¤4å¤±è´¥ï¼Œç»ˆæ­¢åˆ†æ")
            return

        # æ­¥éª¤5: æ‰©å±•åˆ†ææ—¶é—´èŒƒå›´è‡³2025-12-19
        target_date = datetime(2025, 12, 19).date()
        print(f"\\nğŸ¯ å¼€å§‹æ‰©å±•åˆ†ææ—¶é—´èŒƒå›´è‡³ {target_date}")

        if manager.step5_expand_analysis_timerange(target_date):
            print("âœ… æ‰©å±•åˆ†æå®Œæˆ")
        else:
            print("âš ï¸ æ‰©å±•åˆ†æéƒ¨åˆ†å®Œæˆ")

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        manager.generate_final_report()

        print(f"\\nğŸ‰ å…¨é¢è®¾å®šç‚¹å˜æ›´ç›‘æ§åˆ†æå®Œæˆï¼")

    except KeyboardInterrupt:
        print(f"\\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        manager.generate_final_report()
    except Exception as e:
        print(f"\\nâŒ æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()
        manager.generate_final_report()


if __name__ == "__main__":
    main()
